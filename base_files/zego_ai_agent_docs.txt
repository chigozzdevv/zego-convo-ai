Introduction
Overview
Overview
Note
ZEGOCLOUD AI Agent has been fully upgraded and version 2.0 is now released, ZEGOCLOUD has developed a new generation of real-time interactive AI specifically designed for AI agents:

The end-to-end AI voice processing capability has been comprehensively upgraded, achieving over 95% accuracy in recognition and interruption handling, especially in scenarios with double-talk or BGM;
The interactive architecture has been fully optimized to support multi-user and multi-AI interaction scenarios;
The integration experience and usability have been significantly improved.
For more details, please refer to the Release Notes.

What is ZEGOCLOUD AI Agent?
ZEGOCLOUD AI Agent provides SDK and server APIs to help you quickly achieve ultra-low latency IM text and image chatting, voice calls, digital human voice calls, and other interactive features between users and AI agents, thereby fulfilling scenarios such as AI companionship, AI customer service, AI digital human live streaming, etc.

ZEGOCLOUD AI Agent supports custom settings for persona, timbre, appearance, etc., and is compatible with various large language models (LLMs) and text-to-speech services (TTS). It also supports long-term memory, external knowledge bases, and model fine-tuning, thereby delivering a more perfect AI agent.

Why Choose ZEGOCLOUD AI Agent?
Multi-modal Interactive Agent
Customizable Character: You can define the personality and character of AI agents through prompts best practices, combined with RAG, LoRA, etc., to better match roles and meet exclusive needs.
Rich Timbres & Voice Cloning: Over a hundred hyper-realistic timbres suitable for various scenarios such as emotional companionship, customer service, e-commerce, etc., with voice cloning capabilities.
Multi-modal Interaction: Instant text messages, real-time voice calls, video calls, etc.
Extended Premium Photo Digital Human: In as quickly as 200 ms, a single photo is all it takes to generate a real-time interactive AI avatarâ€”complete with precise lip synchronization and lifelike facial rendering.
Real-time Voice Call Capability
Response Delay Reduced to 1 Second Worldwide. ZEGOCLOUD AI Agent adopts fully stream-based processing, leverages our global MSDN (Real-time Sequential Data Network), and achieves an as quick as 1s end-to-end response delay anywhere in the world.
Natural Voice Interruption in 500 ms. ZEGOCLOUD AI Agent rapidly and accurately detects human speech, seamlessly halts its responses within 500 ms upon interruption, and ensures no cross talk even under successive interrupts.
Accurate Speaking-State Detection. While maintaining low response latency, ZEGOCLOUD AI Agent prevents sentence fragments from being split, resulting in more precise AI replies.
AI Audio Processing Capabilities for Agents
AI Noise Reduction (AI ANS). Eliminates environmental noise, music, distant environmental human voices, etc., supporting interactions in various environments such as offices, homes, cars, etc.
AI Voice Activity Detection (AI VAD). Accurately identifies effective human voices, filtering out soft responses like "um", "oh", as well as coughs and other noises resembling human sounds.
AI Echo Cancellation (AI AEC). Precisely eliminates AI voices and background music re-captured by microphones, preventing AI speech from interrupting itself, improving the accuracy of voice when interrupting AI. Also combines functions such as volume ducking and playback volume self-adaptation.
Customized Integration
Easy Integration: With fewer than 10 lines of code, you can embed the AI agent into instant messaging, real-time voice calls, or digital-human conversations in your app.
Flexible Selection of LLM and TTS Plugins: ZEGOCLOUD AI Agent supports multiple vendors both domestic and international, such as ModelArk (Douyin), MiniMax, BytePlus, Alibaba Cloud, Stepfun, etc., and also supports open-source models.
Highly Available, Cost-Efficient Services: By optimizing ASR, LLM, and TTS calls for concurrency and usage, ZEGOCLOUD minimizes end-to-end latency and reduces overall operational costs.
What Can ZEGOCLOUD AI Agent Do?
Module	Function	Description
Voice Calls with AI Agents	Create, Modify, Delete, Query AI Agents	Create an AI agent, including adjusting the basic information description of the AI agent virtual user, including persona (system prompt), timbre, etc., as well as parameters of LLM and TTS used by the agent.
Initiate AI Agent Voice Call	Through creating an AI agent, achieve real-time voice calls with AI with a minimum delay of 1s.
Multi-user Interaction with AI Agent (Beta)	Achieve multi-user interaction with a single AI agent by creating group AI agent instances.
Note
Feature in beta testing, please contact ZEGOCLOUD business for details.
Single user vs multiple AI roles (Beta)	Achieve single user interaction with multiple AI agents by creating AI agent instances and configuring voice color mapping rules.
Note
Feature in beta testing, please contact ZEGOCLOUD Business for details.
AI Audio Processing Capability for AI Interaction	Automatically filters out user-side noise generated during conversations and removes far-field human voices, achieving more precise voice interruption effects and more accurate ASR speech recognition.
Natural Voice Interruption	During real-time voice calls, the AI agent intelligently identifies the user's intention to interrupt the conversation and stops its output.
Real-time Broadcast	The dialogue information between the AI agent and the user will be converted into text in real-time and displayed by the client.
Basic Capabilities	Large Language Model (LLM) Management	Adjust the large language model (LLM) applied by the AI agent.
Commercial LLMs: OpenAI, MiniMax, Qwen, Volcano Ark, Stepfun, ERNIE.
Open-source LLMs compatible with OpenAI Chat Completions API.
Text-to-Speech (TTS) Management	Support for various TTS providers and related capabilities:
Supported service providers: BytePlus (Large Model Voice Synthesis & Streaming Text-to-Speech), Alibaba Cloud (CosyVoice), MiniMax;
Various models, public timbres, voice cloning from vendors, and support for speed and tone adjustments.
Digital Human Management	Integrate digital human images into RTC real-time video interactions based on ZEGO digital human. With premium photo digital humans, you can obtain a 1080P digital human with just a single photo or image, and assign an AI avatar during voice calls.
Add/Delete/Modify AI Agent Instances	Create or delete an AI Agent instance to initiate voice or digital human interaction with the agent.
Get AI Agent Status	Receive corresponding server callbacks to get the AI agent's start speaking and end speaking status; also can query AI agent status API to get states including idle, listening, thinking, speaking, etc.
Interact with AI via IM and makes voice calls	Based on ZIM, implement text message interaction with AI and share memory to initiate voice calls.
Memory (Context) Source	The AI agent's memory (context) can be provided through external input or by binding historical records from In-app Chat (ZIM).
Memory (Context) Update	During the lifecycle of this AI agent instance, record the content of each conversation and use it as subsequent context messages for the agent's memory. Memory can be cleared to restart the conversation.
Memory (Context) Archiving	Convert the dialogue between users and AI agents into text information and store it
Speech Recognition Hot Words	For specialized vocabulary such as role names, temporary hot words can be set to improve speech recognition accuracy.
Proactive LLM Invocation	Simulate user questions by customizing messages sent to LLM, and after LLM responds, send voice to users via TTS. Can be used to implement context-based welcome messages and other scenarios.
Proactive TTS Invocation	TTS can be invoked at any time to achieve AI's proactive broadcasting, thus satisfying scenarios such as AI welcome messages or user reminders. Also supports configuring whether to add to history records and context
Advanced Capabilities	AI Agent Interruption Mode Control	The form of interruption when the agent is speaking can include multiple options, and multiple selections are possible:
Natural voice interruption: When the agent receives voice input, i.e., when the user speaks, it interrupts the agent's speech.
Manual interruption: Control interruption through server-side APIs to enable users to interrupt via buttons or business-side management.
Filter LLM Output and TTS Input	Filtering based on certain rules, such as Chinese and English brackets, emoji expressions, etc., for more controllable AI behavior.
Speech Recognition Segmentation Optimization	Support for voice detection segmentation threshold settings and pause duration settings to achieve balance between delay and voice segmentation.
Best Practices	Role-playing Prompt Optimization	When using AI agents for role-playing, learn how to write system prompts to better showcase the effect.
Better Output with RAG	Support for AI external knowledge base to achieve more basic scripts, company information, and other content.
Memory Module	For longer time spans and where AI needs to remember more basic user information (e.g., age, place of birth, preferences), conduct regular summaries and conclusions to achieve smarter AI interactions.
LoRA, SFT Model Fine-tuning	When there are very high demands for the AI character, fine-tuning of the LLM can be performed. For example, in scenarios where a cloned host replaces a real person.
AI Voice Chat with Cloned Voice	Apply the cloned voice in the voice call process to achieve communication with an AI agent of a specific voice.
Introduction
Release Notes
Release Notes
V2
2025-07-31
Server v2.4.15
New Features

Feature	Description	Documentation
WindowSizeã€LoadMessageCount maximum value adjusted to 200	The MessageHistory.WindowSize and MessageHistory.ZIM.LoadMessageCount fields of the create agent instance/create digital human agent instance interface are adjusted to 200.	Create Agent Instance
Create Digital Human Agent Instance
TTS adds TerminatorText field	The TTS field of the register agent/create/update agent instance interface adds a TerminatorText field. This field can be used to set the termination text of TTS. If the content in the input TTS text matches the TerminatorText string, the content from the TerminatorText string (including) will not be synthesized for this round of TTS.	
Improvements & Optimizations

Optimized the sentence break logic of unidirectional streaming TTS.
2025-06-26
Server v2.4.0
New Features

Feature	Description	Documentation
Digital Human Video Call	Support creating a digital human image in the Digital Human PaaS Service, and create a digital human agent instance to achieve real-time video interaction with the digital human.
Digital human driving latency within 500ms, end-to-end latency within 2s (user speech ends to see AI digital human video).
Ultra-clear digital human video, real 1080P effect.
Realistic facial expressions.
Accurate lip movement. Supports all languages, especially English and Chinese.
Implement Digital Human Video Call
Multi-agent multi-voice output	Support multi-voice output when interacting with multiple AI agents, by actively calling TTS	Send Agent Instance TTS
Improvements & Optimizations

Updated the default model of MiniMax TTS (Text-to-Speech) to speech-02-turbo, and optimized its latency to approximately 300ms.
2025-06-19
Server v2.3.0
New Features

Feature	Description	Documentation
Support retrieving average latency information when instance is destroyed	Latency information includes:
LLM-related latency: First token latency (ms), LLM output speed (tokens/sec)
TTS-related latency: First audio frame latency (ms)
Total server latency (ms)
Get Agent Service Status & Latency Data
Support Alibaba CosyVoice TTS bidirectional streaming	By configuring the Vendor as Alibaba CosyVoice when creating an agent and setting up supported voice tones, you can achieve AI real-time voice calls based on CosyVoice.	-
Support callbacks for agent instance creation success and destruction	Can be used in conjunction with agent instance status query, server exception callback, and agent interruption callback to manage the entire lifecycle process of the agent	Get Agent Service Status & Latency Data
Improvements & Optimizations

During the integration testing period, no separate account application and authentication are required to use services from some ZEGO-supported LLMs (Doubao, MiniMax, Tongyi Qianwen, Stepfun, etc.) and TTS vendors (MiniMax, BytePlus, Alibaba CosyVoice). For details, please refer to Quick Start.
Updated support for MiniMax TTS WebSocket unidirectional streaming, further optimizing latency and voice tone effects.
Reduced end-to-end latency by 100-200ms, can be reduced to under 1 second with technical support enablement.
2025-05-30
Server v2.2.0
New Features

Feature	Description	Documentation
1 user vs multiple AI roles	
Note
Feature is in beta testing, please contact ZEGOCLOUD Business for details.
-
Request body contains agent instance and user information when calling LLM	When creating an agent instance, if the AddAgentInfo field is set to true, the AI Agent backend will add the agent_info field to the request body parameters sent to the custom LLM, which includes room_id, user_id, and agent_instance_id information. This allows for personalized responses based on different users or agent instances, such as calling different function calling or memory based on user IDs.	Configuring LLM
Callback for each round of user speech audio segment	When creating an agent instance, if the UserAudioData field of CallbackConfig is set to 1, the AI Agent backend will callback the audio data of the user's speech in the previous 1-1.5 seconds of each round of conversation (if less than 1 second, no callback will be sent). Business side can implement voiceprint recognition and other capabilities based on this audio information.	Receiving Callback
Improvements & Optimizations

Optimized the user experience problem caused by subtitle and LLM callback too early when ASR multi-sentence concatenation is enabled. For details, please refer to Speech Recognition Segmentation.
2025-05-16
Server v2.1.0
New Features

Feature	Description	Documentation
Multi-user vs 1 Agent	Supports multiple users simultaneously interacting with one AI agent through voice. Features include voice interruption, manual interruption, proactive agent speech, and the agent's ability to distinguish and respond to different users.
Note
Contact ZEGOCLOUD Technical Support for details.
-
Speech Recognition Segmentation	Supports voice detection threshold settings and pause duration settings to balance latency and speech recognition segmentation.	Speech Recognition Segmentation
More TTS Service Providers	Added support for Alibaba Cloud and MiniMax, with bidirectional streaming API support for BytePlus.	Agent Parameter Description - TTS
Interrupt Agent	Supports disabling voice interruption while enabling manual interruption, enabling scenarios like manual interruption and Push-to-talk intercom voice interaction.	Interrupt Agent
Context Management	Supports agent instance-level context management capabilities, including context querying and resetting.	AI Short-term Memory (Agent Context) Management
LLM Content Filtering	Supports filtering LLM output content, enabling emoji filtering and specific word replacement.
Note
Contact ZEGOCLOUD Technical Support for details.
-
Callback Events	Enables developers to receive agent interruption events, user speech behavior, and agent speech behavior through server-side callbacks.	
Get AI Agent Status
Receiving Callback
Improvements & Optimizations

Comprehensive optimization of integration examples, providing business service control pages and supporting client sample code. For details, refer to Quick Start.
Further improved speech recognition and interruption accuracy, especially for external music sounds.
Further optimized voice end-to-end latency, reducing 200ms+ delay.
Added token authentication support for real-time audio and video (RTC), enhancing interaction security without affecting agent interaction.
2025-04-25
Server v2.0.0
Version Update

Enhanced onboarding experience, enabling voice calls with AI agents through less than 10 lines of code.
Upgraded full-process audio handling capabilities, significantly improving the accuracy of speech interruption and recognition, especially in noisy environments, while playing BGM, or during cross talk (AI and user speaking simultaneously), covering various environments such as home, office, and public spaces for AI interaction.
Supports for features including: custom third-party large language models (LLMs), natural speech interruptions within 500ms, real-time subtitles, AI agent status queries, proactive LLM invocation, and proactive TTS invocation.
Upgraded architecture: ZEGOCLOUD AI agent supports multi-user vs multi-AI agent for more flexible interaction formats.
V1
2025-03-21
Server v1.4.0
New Features

Added a Query Agent Status server-side interface.
When creating a session, added a Pass-through Third-party Parameters field to the text-to-speech configuration object.
For Minimax text-to-speech services, the Pass-through Third-party Parameters now includes a Model field.
The ASR configuration object has added Hotwords and Extended Parameters fields.
Added a Remove History field to the request parameters of the server-side interface used for actively invoking text-to-speech services.
2025-02-10
Server v1.3.0
New Features

Added server-side callback for abnormal events.
Added a Sentence Pause Duration field to the text-to-speech configuration object.
2025-01-16
Server v1.2.0
New Features

Added Response Format Types and Response Message Name fields to the large language model configuration object when creating a session.
Added a User ID (required) field to the request parameters of session and conversation-related server-side interfaces, as well as those used for actively invoking large language models and text-to-speech services.
Added API Type and Resource ID fields to the extended parameters of the text-to-speech configuration object.
2025-01-08
Server v1.1.0
New Features

Added a Session ID field to the server-side interface for obtaining session lists, supporting querying session details by session ID.
Added a Conversation History Mode field to the server-side interface for creating sessions, supporting whether to save session history messages.
Improvements & Optimizations

Adjusted room event message protocol.
Deprecated & Removed

Removed the Account Source field from large language model and text-to-speech configuration objects.
2024-12-31
Server v1.0.0
Version Update

Comprehensive service reliability & stability.
Lower end-to-end latency and interruption delay.
Updated audio processing capabilities, supporting noisy environments and meeting over 80% of scenarios.
Agent template library.
Supports active invocation of large language models.
Supports active invocation of text-to-speech services.
Supports custom RAG and other capabilities.
Added an Ignore Bracketed Text field to the large language model configuration object, supporting filtering out emojis from large language model texts.
Beta
2024-12-16
Server v0.5.0
New Features

Added a server-side interface for proactively calling the text-to-speech service.
Added a server-side interface for proactively calling the large language model service.
Added a server-side callback interface for obtaining results from the large language model service.
The session creation server-side interface added an Enable Large Language Model Server Message configuration.
The large language model configuration object added an Ignore Bracketed Text field, supporting filtering of emoticons in the large language model's text.
Improvements and Optimizations

Unified the Timestamp field for customizing per-round conversation prompts with the large language model to Int type.
2024-12-05
Server v0.3.0
New Features

Added a Conversation Configuration field to server-side interfaces for creating, updating, and querying sessions.
Added a protocol for a custom pre-processing server-side interface for large language model prompts.
The text-to-speech configuration object added Ignore Bracketed Text and Ignore Custom Bracketed Text fields, supporting ignoring certain input content for text-to-speech services, such as content within Chinese and English brackets.
2024-11-26
Server v0.2.0
New Features

Added an Extended Parameters field applicable to text-to-speech services, supporting replicated voices from BytePlus and Minimax.
Added error codes such as 410003101.
Bug Fixes

Fixed an issue where the AI agent could not interrupt properly under certain scenarios.
2024-10-01
Server v0.1.0
Version Release

Supports basic scenarios such as AI real-time voice calls and IM text chats.
Supports switching between large language models (LLMs), text-to-speech (TTS) service providers, and voice tones.
Quick Start
Quick Start Voice Call
Quick Start Voice Call
This document explains how to quickly integrate the client SDK (ZEGO Express SDK) and achieve voice interaction with an AI Agent.

Prerequisites
Create a project in the ZEGOCLOUD Console, and get its valid AppID and AppSign. For more details, please refer to Admin Console doc How to view project info.
Deploy your server to call ZEGOCLOUD AI Agent server APIs (you can refer to the server example code).
Sample Codes
The following is the example code for the business backend that integrates the real-time interactive AI Agent API. You can refer to the example code to implement your own business logic.

Business Backend Example Code
Includes the basic capabilities of obtaining ZEGOCLOUD Token, registering AI Agent, creating AI Agent instances, and deleting AI Agent instances.

Below are the client sample codes, you can refer to these sample codes to implement your own business logic.

Web Client Sample Code
Web client sample code. It includes basic capabilities such as logging into and out of RTC rooms, and publishing and playing streams.

The following video demonstrates how to run the server and client (Web) sample code and interact with an AI agent by voice.


Overall Business Process
Server side: Follow the Server Quick Start guide to run the server sample code and deploy your server
Integrate ZEGOCLOUD AI Agent APIs to manage AI agents.
Client side: Run the sample code
Create and manage AI agents through your server.
Integrate ZEGO Express SDK for real-time communication.
After completing these two steps, you can add an AI agent to a room for real-time interaction with real users.

ZEGOCLOUD AI Agent Server
Your Server
Client
ZEGOCLOUD AI Agent Server
Your Server
Client
Register an AI agent
Register an AI agent
â€‹
Notify server to start call
Create an AI agent instance
The AI agent logs into the RTC room, publishes a stream, and plays the user stream
â€‹
â€‹
Request Token
Token
Initialize ZEGO Express SDK, login to room and start publishing stream
User plays the AI agent stream
Notify server to stop call
Delete the AI agent instance
â€‹
â€‹
User stops publishing the stream and exits the room
Core Capability Implementation
Integrate ZEGO Express SDK
Please refer to Integrate SDK > Method 2 to use npm to integrate SDK v3.9.123 or above. After integrating the SDK, initialize ZegoExpressEngine as follows.

Instantiate ZegoExpressEngine
Check system requirements (WebRTC support and microphone permissions)
import { ZegoExpressEngine } from "zego-express-engine-webrtc";

const appID = 1234567 // Obtain from ZEGOCLOUD Console
const server = 'xxx' // Obtain from ZEGOCLOUD Console

// Instantiate ZegoExpressEngine with appId and server configurations
// !mark
const zg = new ZegoExpressEngine(appID, server);
// Check system requirements
// !mark
const checkSystemRequirements = async () => {
    // Detect WebRTC support
    const rtc_sup = await zg.checkSystemRequirements("webRTC");
    if (!rtc_sup.result) {
      // Browser does not support WebRTC
  }
    // Detect microphone permission status
    const mic_sup = await zg.checkSystemRequirements("microphone");
    if (!mic_sup.result) {
      // Microphone permission is not enabled
  }
}
checkSystemRequirements()

import { ZegoExpressEngine } from "zego-express-engine-webrtc";

const appID = 1234567 // Obtain from ZEGOCLOUD Console
const server = 'xxx' // Obtain from ZEGOCLOUD Console

// Instantiate ZegoExpressEngine with appId and server configurations
const zg = new ZegoExpressEngine(appID, server);
// Check system requirements
const checkSystemRequirements = async () => {
    // Detect WebRTC support
    const rtc_sup = await zg.checkSystemRequirements("webRTC");
    if (!rtc_sup.result) {
      // Browser does not support WebRTC
  }
    // Detect microphone permission status
    const mic_sup = await zg.checkSystemRequirements("microphone");
    if (!mic_sup.result) {
      // Microphone permission is not enabled
  }
}
checkSystemRequirements()
Notify Your Server to Start Call
You can notify your server to start the call immediately after the real user enters the room on the client side. Asynchronous calls can help reduce call connection time. After receiving the start call notification, your server creates an AI agent instance using the same roomID and associated userID and streamID as the client, so that the AI agent can interact with real users in the same room through mutual stream publishing and playing.

Sample Code for Notifying Your Server
// Notify your server to start call
async function startCall() {
  try {
    const response = await fetch(`${YOUR_SERVER_URL}/api/start`, { // YOUR_SERVER_URL is the address of your Your Server
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      }
    });

    const data = await response.json();
    console.log('Start call result:', data);
    return data;
  } catch (error) {
    console.error('Failed to start call:', error);
    throw error;
  }
}

User logs in a RTC room and starts publishing a stream
After a real user logs into the room, they start publishing streams.

The token used for login needs to be obtained from your server; please refer to the complete sample code.

Note
Please ensure that the roomID, userID, and streamID are unique under one ZEGOCLOUD APPID.

roomID: Generated by the user according to their own rules, it will be used to log into the Express SDK room. Only numbers, English characters, and '~', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+', '=', '-', '`', ';', ''', ',', '.', '<', '>', '' are supported. If interoperability with the Web SDK is required, do not use '%'.
userID: Length should not exceed 32 bytes. Only numbers, English characters, and '~', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+', '=', '-', '`', ';', ''', ',', '.', '<', '>', '' are supported. If interoperability with the Web SDK is required, do not use '%'.
streamID: Length should not exceed 256 bytes. Only numbers, English characters, and '-', '_' are supported.
Client login to room and publish a stream
const userId = "" // User ID for logging into the Express SDK room
const roomId = "" // RTC Room ID
const userStreamId = "" // User stream push ID
async function enterRoom() {
  try {
    // Generate RTC Token [Reference Documentation] (https://www.zegocloud.com/docs/video-call/token?platform=web&language=javascript)
    const token = await Api.getToken();
    // Login to room
    await zg.loginRoom(roomId, token, {
      userID: userId,
      userName: "",
    });

    // Create local audio stream
    const localStream = await zg.createZegoStream({
      camera: {
        video: false,
        audio: true,
      },
    });
    if (localStream) {
// !mark(1:2)
      // Push local stream
      await zg.startPublishingStream(userStreamId, localStream);
    }
  } catch (error) {
    console.error("Failed to enter room:", error);
    throw error;
  }
}
enterRoom()
Client login to room and publish a stream

const userId = "" // User ID for logging into the Express SDK room
const roomId = "" // RTC Room ID
const userStreamId = "" // User stream push ID
async function enterRoom() {
  try {
    // Generate RTC Token [Reference Documentation] (https://www.zegocloud.com/docs/video-call/token?platform=web&language=javascript)
    const token = await Api.getToken();
    // Login to room
    await zg.loginRoom(roomId, token, {
      userID: userId,
      userName: "",
    });

    // Create local audio stream
    const localStream = await zg.createZegoStream({
      camera: {
        video: false,
        audio: true,
      },
    });
    if (localStream) {
      // Push local stream
      await zg.startPublishingStream(userStreamId, localStream);
    }
  } catch (error) {
    console.error("Failed to enter room:", error);
    throw error;
  }
}
enterRoom()
Play the AI Agent Stream
By default, there is only one real user and one AI agent in the same room, so any new stream added is assumed to be the AI agent stream.

Client request to play the AI agent stream
// Listen to remote stream update events
function setupEvent() {
  zg.on("roomStreamUpdate",
    async (roomID, updateType, streamList) => {
      if (updateType === "ADD" && streamList.length > 0) {
        try {
          for (const stream of streamList) {
            // Play the AI agent stream
// !mark
            const mediaStream = await zg.startPlayingStream(stream.streamID);
            if (!mediaStream) return;
            const remoteView = await zg.createRemoteStreamView(mediaStream);
            if (remoteView) {
             // A container with the id 'remoteSteamView' is required on the page to receive the AI agent stream [Reference Documentation]ï¼ˆhttps://www.zegocloud.com/article/api?doc=Express_Video_SDK_API~javascript_web~class~ZegoStreamViewï¼‰
              remoteView.play("remoteSteamView", {
                enableAutoplayDialog: false,
              });
            }
          }
        } catch (error) {
          console.error("Failed to pull stream:", error);
        }
      }
    }
  );
}
Client request to play the AI agent stream

// Listen to remote stream update events
function setupEvent() {
  zg.on("roomStreamUpdate",
    async (roomID, updateType, streamList) => {
      if (updateType === "ADD" && streamList.length > 0) {
        try {
          for (const stream of streamList) {
            // Play the AI agent stream
            const mediaStream = await zg.startPlayingStream(stream.streamID);
            if (!mediaStream) return;
            const remoteView = await zg.createRemoteStreamView(mediaStream);
            if (remoteView) {
             // A container with the id 'remoteSteamView' is required on the page to receive the AI agent stream [Reference Documentation]ï¼ˆhttps://www.zegocloud.com/article/api?doc=Express_Video_SDK_API~javascript_web~class~ZegoStreamViewï¼‰
              remoteView.play("remoteSteamView", {
                enableAutoplayDialog: false,
              });
            }
          }
        } catch (error) {
          console.error("Failed to pull stream:", error);
        }
      }
    }
  );
}
CongratulationsðŸŽ‰! After completing this step, you can ask the AI agent any question by voice, and the AI agent will answer your questions by voice!

Delete the agent instance and the user exits the room
The client calls the logout interface to exit the room and stops publishing and playing streams. At the same time, it notifies your server to end the call. After receiving the end call notification, your server will delete the AI agent instance, and the AI agent instance will automatically exit the room and stop publishing and playing streams. This completes a full interaction.

// Exit room
async function stopCall() {
  try {
// !mark
    const response = await fetch(`${YOUR_SERVER_URL}/api/stop`, { // YOUR_SERVER_URL is the address of your Your Server
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      }
    });

    const data = await response.json();
    console.log('End call result:', data);
    return data;
  } catch (error) {
    console.error('Failed to end call:', error);
    throw error;
  }
}
stopCall();
zg.destroyLocalStream(localStream);
// !mark
zg.logoutRoom();

// Exit room
async function stopCall() {
  try {
    const response = await fetch(`${YOUR_SERVER_URL}/api/stop`, { // YOUR_SERVER_URL is the address of your Your Server
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      }
    });

    const data = await response.json();
    console.log('End call result:', data);
    return data;
  } catch (error) {
    console.error('Failed to end call:', error);
    throw error;
  }
}
stopCall();
zg.destroyLocalStream(localStream);
zg.logoutRoom();
This is the complete core process for you to achieve real-time voice interaction with an AI agent.

Best Practices for ZEGO Express SDK Configuration
To achieve the best audio call experience, it is recommended to configure the ZEGO Express SDK according to the following best practices. These configurations can significantly improve the quality of AI agent voice interactions.

Enable traditional audio 3A processing (Acoustic Echo Cancellation AEC, Automatic Gain Control AGC, and Noise Suppression ANS)
Set the room usage scenario to High Quality Chatroom, as the SDK will adopt different optimization strategies for different scenarios
When pushing streams, configure the push parameters to automatically switch to available videoCodec
// Import necessary modules
import { ZegoExpressEngine } from "zego-express-engine-webrtc";
import { VoiceChanger } from "zego-express-engine-webrtc/voice-changer";

// Load audio processing module, must be called before new ZegoExpressEngine
ZegoExpressEngine.use(VoiceChanger);

// Instantiate ZegoExpressEngine, set room usage scenario to High Quality Chatroom
const zg = new ZegoExpressEngine(appid, server, { scenario: 7 })

// Traditional audio 3A processing is enabled by default in SDK

// Create local media stream
const localStream = await zg.createZegoStream();

// Push local media stream, need to set automatic switching to available videoCodec
await zg.startPublishingStream(userStreamId, localStream, {
  enableAutoSwitchVideoCodec: true,
});

// Check system requirements
async function checkSystemRequirements() {
  // Check WebRTC support
  const rtcSupport = await zg.checkSystemRequirements("webRTC");
  if (!rtcSupport.result) {
    console.error("Browser does not support WebRTC");
    return false;
  }

  // Check microphone permission
  const micSupport = await zg.checkSystemRequirements("microphone");
  if (!micSupport.result) {
    console.error("Microphone permission not granted");
    return false;
  }

  return true;
}

// Import necessary modules
import { ZegoExpressEngine } from "zego-express-engine-webrtc";
import { VoiceChanger } from "zego-express-engine-webrtc/voice-changer";

// Load audio processing module, must be called before new ZegoExpressEngine
ZegoExpressEngine.use(VoiceChanger);

// Instantiate ZegoExpressEngine, set room usage scenario to High Quality Chatroom
const zg = new ZegoExpressEngine(appid, server, { scenario: 7 })

// Traditional audio 3A processing is enabled by default in SDK

// Create local media stream
const localStream = await zg.createZegoStream();

// Push local media stream, need to set automatic switching to available videoCodec
await zg.startPublishingStream(userStreamId, localStream, {
  enableAutoSwitchVideoCodec: true,
});

// Check system requirements
async function checkSystemRequirements() {
  // Check WebRTC support
  const rtcSupport = await zg.checkSystemRequirements("webRTC");
  if (!rtcSupport.result) {
    console.error("Browser does not support WebRTC");
    return false;
  }

  // Check microphone permission
  const micSupport = await zg.checkSystemRequirements("microphone");
  if (!micSupport.result) {
    console.error("Microphone permission not granted");
    return false;
  }

  return true;
}
Additional Optimization Recommendations
Browser Compatibility: Recommended to use the latest versions of modern browsers such as Chrome, Firefox, Safari
Network Environment: Ensure stable network connection, recommend using wired network or Wi-Fi with good signal
Audio Equipment: Use high-quality microphones and speakers
Page Optimization: Avoid running too many JavaScript tasks on the same page, which may affect audio processing performance
HTTPS Environment: Use HTTPS protocol in production environment to ensure microphone permission access
Listen for Exception Callback
Note
Due to the large number of parameters for LLM and TTS, it is easy to cause various abnormal problems such as the AI agent not answering or not speaking during the test process due to parameter configuration errors. We strongly recommend that you listen for exception callbacks during the test process and quickly troubleshoot problems based on the callback information.
Receive Callback
Click to view the guide for listening to exception callbacks. The event with Event as Exception can be quickly located through Data.Code and Data.Message.
Notify Your Server to Start Call
You can notify your server to start the call immediately after the real user enters the room on the client side. Asynchronous calls can help reduce call connection time. After receiving the start call notification, your server creates an AI agent instance using the same roomID and associated userID and streamID as the client, so that the AI agent can interact with real users in the same room through mutual stream publishing and playing.

Sample Code for Notifying Your Server
Note
In the following examples, roomID, userID, streamID and other parameters are not passed when notifying your server to start the call because fixed values have been agreed between the client and your server in this example. In actual use, please pass the real parameters according to your business requirements.
// Notify your server to start call
async function startCall() {
  try {
    const response = await fetch(`${YOUR_SERVER_URL}/api/start`, { // YOUR_SERVER_URL is the address of your Your Server
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      }
    });

    const data = await response.json();
    console.log('Start call result:', data);
    return data;
  } catch (error) {
    console.error('Failed to start call:', error);
    throw error;
  }
}

// Notify your server to start call
async function startCall() {
  try {
    const response = await fetch(`${YOUR_SERVER_URL}/api/start`, { // YOUR_SERVER_URL is the address of your Your Server
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      }
    });

    const data = await response.json();
    console.log('Start call result:', data);
    return data;
  } catch (error) {
    console.error('Failed to start call:', error);
    throw error;
  }
}Quick Start
Quick Start with Digital Human
Quick Start Digital Human Video Call
This document explains how to quickly integrate the client SDK (ZEGO Express SDK and Digital Human SDK) and achieve video interaction with an AI Agent.

Digital Human Introduction
With just a photo or image of a real person or anime character from the waist up, you can obtain a 1080P digital human with accurate lip-sync and realistic appearance. When used with the AI Agent product, you can quickly achieve video interaction chat with AI digital humans within 2 seconds overall, suitable for various scenarios such as digital human 1V1 interactive video, digital human customer service, and digital human live streaming.

More natural driving effects: Supports subtle body movements, natural facial expressions without distortion, providing more realistic and immersive interaction compared to voice calls;
Multi-language accurate lip-sync: Natural and accurate lip movements, especially optimized for Chinese and English;
Ultra-low interaction latency: Digital human driving latency < 500ms, combined with AI Agent interaction latency < 2s;
Higher clarity: True 1080P effect, 20%+ improvement in clarity compared to traditional image-based digital humans

Prerequisites
Create a project in the ZEGOCLOUD Console, and get its valid AppID and AppSign. For more details, please refer to Admin Console doc How to view project info.
You have contacted ZEGOCLOUD Technical Support to enable Digital Human PaaS service and related interface permissions.
You have contacted ZEGOCLOUD Technical Support to create a digital human.
You have integrated AI Agent related server APIs according to the Business Backend Quick Start Guide.
Sample Code
The following is the example code for the business backend that integrates the real-time interactive AI Agent API. You can refer to the example code to implement your own business logic.

Business Backend Example Code
Includes the basic capabilities of obtaining ZEGOCLOUD Token, registering AI Agent, creating AI Agent instances, and deleting AI Agent instances.

Below are client sample codes. You can refer to the sample code to implement your own business logic.

Web Client Sample Code
Includes basic capabilities such as login, publishing, subscribing, and exiting room.

The following video demonstrates how to run the server and client (Web) sample code and interact with the digital human agent via video.


Overall Business Process
Server, deploy the business backend sample code according to the Business Backend Quick Start Guide.
Integrate the AI Agent API management of the AI Agent.
Client, run the sample code.
Create and manage agents through the business backend.
Integrate ZEGO Express SDK to complete real-time communication.
After completing the above two steps, you can achieve real-time interaction with the AI Agent in the room and with the real user.

AI Agent Backend
Business Backend
Client
AI Agent Backend
Business Backend
Client
Register Agent
Register Agent
â€‹
Notify Business Backend to Start Call
Create Digital Human Agent Instance
Digital Human Agent Login Room and Push Stream, Pull
Digital Human Configuration
Initialize Digital Human SDK and Set Digital Human Configuration
Request Token
Token
Initialize ZEGO Express SDK and Login Room and Push Stream
User play Agent Stream and Pass Frame Data and SEI Data to Digital Human SDK
Notify Business Backend to Stop Call
Delete Agent Instance
â€‹
â€‹
User Stop Push Stream and Exit Room
User Exit Digital Human SDK
Core Capabilities Implementation
Integrate ZEGO Express SDK
Please refer to Integrate SDK > Method 2 to use npm to integrate SDK v3.9.123 or above. After integrating the SDK, initialize ZegoExpressEngine as follows.

Instantiate ZegoExpressEngine
Check system requirements (WebRTC support and microphone permissions)
import { ZegoExpressEngine } from "zego-express-engine-webrtc";

const appID = 1234567 // Get appId from ZEGO Console
const server = 'xxx' // Get server from ZEGO Console

// Instantiate ZegoExpressEngine with appId and server configurations
// !mark
const zg = new ZegoExpressEngine(appID, server);
// Check system requirements
// !mark
const checkSystemRequirements = async () => {
    // Detect whether WebRTC is supported
    const rtc_sup = await zg.checkSystemRequirements("webRTC");
    if (!rtc_sup.result) {
      // Browser does not support WebRTC
  }
    // Detect whether microphone permission is enabled
    const mic_sup = await zg.checkSystemRequirements("microphone");
    if (!mic_sup.result) {
      // Microphone permission is not enabled
  }
}
checkSystemRequirements()

import { ZegoExpressEngine } from "zego-express-engine-webrtc";

const appID = 1234567 // Get appId from ZEGO Console
const server = 'xxx' // Get server from ZEGO Console

// Instantiate ZegoExpressEngine with appId and server configurations
const zg = new ZegoExpressEngine(appID, server);
// Check system requirements
const checkSystemRequirements = async () => {
    // Detect whether WebRTC is supported
    const rtc_sup = await zg.checkSystemRequirements("webRTC");
    if (!rtc_sup.result) {
      // Browser does not support WebRTC
  }
    // Detect whether microphone permission is enabled
    const mic_sup = await zg.checkSystemRequirements("microphone");
    if (!mic_sup.result) {
      // Microphone permission is not enabled
  }
}
checkSystemRequirements()
Notify Business Backend to Start Call
You can notify the business backend to start the call immediately after the real user enters the room. The asynchronous call can reduce the call connection time. After the business backend receives the start call notification, it creates a digital human agent instance using the same roomID and associated userID and streamID as the client, so that the digital human agent can interact with the real user in the same room through mutual push and pull streams.

When requesting the business backend, you need to include the digital human parameters, which include digital_human_id and config_id.

Note
digital_human_id: The digital human ID, please contact ZEGO technical support to obtain it. Test with public ID: c4b56d5c-db98-4d91-86d4-5a97b507da97.
config_id: The configuration ID of the digital human, different platforms use different digital human configurations, and the digital human service will optimize the performance and effect on different platforms according to the config_id. For Android/iOS, please fill in mobile, and for Web, please fill in web.
Example Code for Notifying the Business Backend to Start Call
// Notify the business backend to start the call
async function startCall() {
  try {
    const response = await fetch(`${YOUR_SERVER_URL}/api/start-digital-human`, { // YOUR_SERVER_URL is your business backend address
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      }
    });

    const data = await response.json();
    console.log('Start call result:', data);
    return data;
  } catch (error) {
    console.error('Start call failed:', error);
    throw error;
  }
}

User logs in a RTC room and starts publishing a stream
After a real user logs into the room, they start publishing streams.

The token used for login needs to be obtained from your server; please refer to the complete sample code.

Note
Please ensure that the roomID, userID, and streamID are unique under one ZEGOCLOUD APPID.

roomID: Generated by the user according to their own rules, it will be used to log into the Express SDK room. Only numbers, English characters, and '~', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+', '=', '-', '`', ';', ''', ',', '.', '<', '>', '' are supported. If interoperability with the Web SDK is required, do not use '%'.
userID: Length should not exceed 32 bytes. Only numbers, English characters, and '~', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+', '=', '-', '`', ';', ''', ',', '.', '<', '>', '' are supported. If interoperability with the Web SDK is required, do not use '%'.
streamID: Length should not exceed 256 bytes. Only numbers, English characters, and '-', '_' are supported.
Client login to room and publish a stream
const userId = "" // User ID for logging into the Express SDK room
const roomId = "" // RTC Room ID
const userStreamId = "" // User stream push ID
async function enterRoom() {
  try {
    // Generate RTC Token [Reference Documentation] (https://www.zegocloud.com/docs/video-call/token?platform=web&language=javascript)
    const token = await Api.getToken();
    // Login to room
    await zg.loginRoom(roomId, token, {
      userID: userId,
      userName: "",
    });

    // Create local audio stream
    const localStream = await zg.createZegoStream({
      camera: {
        video: false,
        audio: true,
      },
    });
    if (localStream) {
// !mark(1:2)
      // Push local stream
      await zg.startPublishingStream(userStreamId, localStream);
    }
  } catch (error) {
    console.error("Failed to enter room:", error);
    throw error;
  }
}
enterRoom()
Client login to room and publish a stream

const userId = "" // User ID for logging into the Express SDK room
const roomId = "" // RTC Room ID
const userStreamId = "" // User stream push ID
async function enterRoom() {
  try {
    // Generate RTC Token [Reference Documentation] (https://www.zegocloud.com/docs/video-call/token?platform=web&language=javascript)
    const token = await Api.getToken();
    // Login to room
    await zg.loginRoom(roomId, token, {
      userID: userId,
      userName: "",
    });

    // Create local audio stream
    const localStream = await zg.createZegoStream({
      camera: {
        video: false,
        audio: true,
      },
    });
    if (localStream) {
      // Push local stream
      await zg.startPublishingStream(userStreamId, localStream);
    }
  } catch (error) {
    console.error("Failed to enter room:", error);
    throw error;
  }
}
enterRoom()
Play the AI Agent Stream
By default, there is only one real user and one AI agent in the same room, so any new stream added is assumed to be the AI agent stream.

Client
// Listen for remote stream update events
function setupEvent() {
  zg.on("roomStreamUpdate",
    async (roomID, updateType, streamList) => {
      if (updateType === "ADD" && streamList.length > 0) {
        try {
          for (const stream of streamList) {
            // Pull the AI agent stream
// !mark
            const mediaStream = await zg.startPlayingStream(stream.streamID);
            if (!mediaStream) return;
            const remoteView = await zg.createRemoteStreamView(mediaStream);
            if (remoteView) {
             // Here you need to have a container with an id of remoteSteamView to receive the AI agent stream [Reference Documentation]ï¼ˆhttps://docs.zegocloud.com/article/api?doc=Express_Video_SDK_API~javascript_web~class~ZegoStreamViewï¼‰
              remoteView.play("remoteSteamView", {
                enableAutoplayDialog: false,
              });
            }
          }
        } catch (error) {
          console.error("Pull stream failed:", error);
        }
      }
    }
  );
}
Client

// Listen for remote stream update events
function setupEvent() {
  zg.on("roomStreamUpdate",
    async (roomID, updateType, streamList) => {
      if (updateType === "ADD" && streamList.length > 0) {
        try {
          for (const stream of streamList) {
            // Pull the AI agent stream
            const mediaStream = await zg.startPlayingStream(stream.streamID);
            if (!mediaStream) return;
            const remoteView = await zg.createRemoteStreamView(mediaStream);
            if (remoteView) {
             // Here you need to have a container with an id of remoteSteamView to receive the AI agent stream [Reference Documentation]ï¼ˆhttps://docs.zegocloud.com/article/api?doc=Express_Video_SDK_API~javascript_web~class~ZegoStreamViewï¼‰
              remoteView.play("remoteSteamView", {
                enableAutoplayDialog: false,
              });
            }
          }
        } catch (error) {
          console.error("Pull stream failed:", error);
        }
      }
    }
  );
}
CongratulationsðŸŽ‰! After completing this step, you can now ask the AI agent any questions, and the AI agent will answer your questions!

Exit the Room and End the Call
The client calls the logout interface to exit the room and stop the push and pull streams. At the same time, it notifies the business backend that the call has ended. After the business backend receives the end call notification, it will delete the AI agent instance, and the AI agent instance will automatically exit the room and stop the push and pull streams. Finally, call the digital human SDK exit interface, so that a complete interactive session is completed.

// Exit the room
async function stopCall() {
  try {
// !mark
    const response = await fetch(`${YOUR_SERVER_URL}/api/stop`, { // YOUR_SERVER_URL is your business backend address
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      }
    });

    const data = await response.json();
    console.log('End call result:', data);
    return data;
  } catch (error) {
    console.error('End call failed:', error);
    throw error;
  }
}
stopCall();
zg.destroyLocalStream(localStream);
// !mark
zg.logoutRoom();

// Exit the room
async function stopCall() {
  try {
    const response = await fetch(`${YOUR_SERVER_URL}/api/stop`, { // YOUR_SERVER_URL is your business backend address
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      }
    });

    const data = await response.json();
    console.log('End call result:', data);
    return data;
  } catch (error) {
    console.error('End call failed:', error);
    throw error;
  }
}
stopCall();
zg.destroyLocalStream(localStream);
zg.logoutRoom();
This is the complete core process for you to implement real-time interaction with the digital human agent.

Best Practices for ZEGO Express SDK Configuration
To achieve the best audio call experience, it is recommended to configure the ZEGO Express SDK according to the following best practices. These configurations can significantly improve the quality of AI agent voice interactions.

Enable traditional audio 3A processing (Acoustic Echo Cancellation AEC, Automatic Gain Control AGC, and Noise Suppression ANS)
Set the room usage scenario to High Quality Chatroom, as the SDK will adopt different optimization strategies for different scenarios
When pushing streams, configure the push parameters to automatically switch to available videoCodec
// Import necessary modules
import { ZegoExpressEngine } from "zego-express-engine-webrtc";
import { VoiceChanger } from "zego-express-engine-webrtc/voice-changer";

// Load audio processing module, must be called before new ZegoExpressEngine
ZegoExpressEngine.use(VoiceChanger);

// Instantiate ZegoExpressEngine, set room usage scenario to High Quality Chatroom
const zg = new ZegoExpressEngine(appid, server, { scenario: 7 })

// Traditional audio 3A processing is enabled by default in SDK

// Create local media stream
const localStream = await zg.createZegoStream();

// Push local media stream, need to set automatic switching to available videoCodec
await zg.startPublishingStream(userStreamId, localStream, {
  enableAutoSwitchVideoCodec: true,
});

// Check system requirements
async function checkSystemRequirements() {
  // Check WebRTC support
  const rtcSupport = await zg.checkSystemRequirements("webRTC");
  if (!rtcSupport.result) {
    console.error("Browser does not support WebRTC");
    return false;
  }
  
  // Check microphone permission
  const micSupport = await zg.checkSystemRequirements("microphone");
  if (!micSupport.result) {
    console.error("Microphone permission not granted");
    return false;
  }
  
  return true;
}

// Import necessary modules
import { ZegoExpressEngine } from "zego-express-engine-webrtc";
import { VoiceChanger } from "zego-express-engine-webrtc/voice-changer";

// Load audio processing module, must be called before new ZegoExpressEngine
ZegoExpressEngine.use(VoiceChanger);

// Instantiate ZegoExpressEngine, set room usage scenario to High Quality Chatroom
const zg = new ZegoExpressEngine(appid, server, { scenario: 7 })

// Traditional audio 3A processing is enabled by default in SDK

// Create local media stream
const localStream = await zg.createZegoStream();

// Push local media stream, need to set automatic switching to available videoCodec
await zg.startPublishingStream(userStreamId, localStream, {
  enableAutoSwitchVideoCodec: true,
});

// Check system requirements
async function checkSystemRequirements() {
  // Check WebRTC support
  const rtcSupport = await zg.checkSystemRequirements("webRTC");
  if (!rtcSupport.result) {
    console.error("Browser does not support WebRTC");
    return false;
  }
  
  // Check microphone permission
  const micSupport = await zg.checkSystemRequirements("microphone");
  if (!micSupport.result) {
    console.error("Microphone permission not granted");
    return false;
  }
  
  return true;
}
Additional Optimization Recommendations
Browser Compatibility: Recommended to use the latest versions of modern browsers such as Chrome, Firefox, Safari
Network Environment: Ensure stable network connection, recommend using wired network or Wi-Fi with good signal
Audio Equipment: Use high-quality microphones and speakers
Page Optimization: Avoid running too many JavaScript tasks on the same page, which may affect audio processing performance
HTTPS Environment: Use HTTPS protocol in production environment to ensure microphone permission access
Listen for Exception Callback
Note
Due to the large number of parameters for LLM and TTS, it is easy to cause various abnormal problems such as the AI agent not answering or not speaking during the test process due to parameter configuration errors. We strongly recommend that you listen for exception callbacks during the test process and quickly troubleshoot problems based on the callback information.
Receive Callback
Click to view the guide for listening to exception callbacks. The event with Event as Exception can be quickly located through Data.Code and Data.Message.
Basic
Display Subtitles
Display Subtitles
This article introduces how to display subtitles during a voice call between a user and an AI agent. As follows:

User's speech: Stream the user's spoken content as it is being recognized by ASR in real time.
AI agent's speech: Stream the AI agent's output content as it is being generated by LLM in real time.
image.png
Prerequisites
You should have already integrated the ZEGO Express SDK and the ZEGOCLOUD AI Agent, and implemented a basic voice-call feature following the Quick Start doc.

Quick Implementation
During voice conversations between users and AI agents, the ZEGOCLOUD AI Agent server sends ASR recognition text and LLM response text via custom messages in the RTC room to the client. By listening for these custom messages, the client can parse the status events and render the UI.

The processing flowchart for RTC room custom messages is as follows:

Cmd=3

Cmd=4

Start

Implement onRecvExperimentalAPI callback and initialize subtitle UI component

Parse RTC room custom messages

Process ASR text

Process LLM text

Sort and update user subtitles

Sort and update AI agent subtitles

Clear message cache after message ends

End

Listening to Custom Room Messages
By listening to the recvExperimentalAPI callback, the client can obtain room custom messages with method as onRecvRoomChannelMessage. Below is an example of the callback listener code:

// WARNING!!!: The data received through custom room messages may be out of order, and sorting needs to be performed based on the SeqId field.
// !mark
zg.on("recvExperimentalAPI", (result) => {
  const { method, content } = result;
// !mark
  if (method === "onRecvRoomChannelMessage") {
    try {
      // Parse the message
      const recvMsg = JSON.parse(content.msgContent);
      const { Cmd, SeqId, Data, Round } = recvMsg;
    } catch (error) {
      console.error("Failed to parse the message:", error);
    }
  }
});
// Enable the experimental API for onRecvRoomChannelMessage
// !mark
zg.callExperimentalAPI({ method: "onRecvRoomChannelMessage", params: {} });

// WARNING!!!: The data received through custom room messages may be out of order, and sorting needs to be performed based on the SeqId field.
zg.on("recvExperimentalAPI", (result) => {
  const { method, content } = result;
  if (method === "onRecvRoomChannelMessage") {
    try {
      // Parse the message
      const recvMsg = JSON.parse(content.msgContent);
      const { Cmd, SeqId, Data, Round } = recvMsg;
    } catch (error) {
      console.error("Failed to parse the message:", error);
    }
  }
});
// Enable the experimental API for onRecvRoomChannelMessage
zg.callExperimentalAPI({ method: "onRecvRoomChannelMessage", params: {} });
Room Custom Message Protocol
The fields of the room custom message are described as follows:

Field	Type	Description
Timestamp	Number	Timestamp, at the second level
SeqId	Number	Packet sequence number, may be out of order. Please sort the messages according to the sequence number. In extreme cases, the Id may not be continuous.
Round	Number	Dialogue round, increases each time the user starts speaking
Cmd	Number	
3: ASR text.
4: LLM text.
Data	Object	Specific content, different Cmds correspond to different Data
Data varies depending on the Cmd as follows:

Cmd is 3
Cmd is 4
Field	Type	Description
Text	String	ASR text of user speech.
Each issuance is the full text, supporting text correction.
MessageId	String	Message ID. It is unique for each round of ASR text message.
EndFlag	Bool	End flag, true indicates that the ASR text of this round has been processed.

Processing Logic
Determine the message type based on the Cmd field, and obtain the message content from the Data field.

Cmd is 3, ASR Text
Cmd is 4, LLM Text
 // Handle user message
 function handleUserMessage(data, seqId, round) {
    if (data.EndFlag) {
      // User has finished speaking
    }
    const content = data.Text;
    if (content) {
      // Use the ASR text corresponding to the latest seqId as the latest speech recognition result and update the UI
    }
 }

 // Handle user message
 function handleUserMessage(data, seqId, round) {
    if (data.EndFlag) {
      // User has finished speaking
    }
    const content = data.Text;
    if (content) {
      // Use the ASR text corresponding to the latest seqId as the latest speech recognition result and update the UI
    }
 }
The corresponding message processing flow is shown in the figure below:

image.png

Use the subtitle component
If you are working on a Vue project, you can download the subtitle component to your project and use it directly.

Vue Project Subtitle Component Usage Example
// Example code for using the subtitle component
// Import the chatHook in your page
import { useChat } from "useChat";
import { onMounted, onBeforeUnmount } from 'vue';

// Call the useChat method, pass in the Express SDK instance. The messages will be rendered in your subtitle component.
const { messages, setupEventListeners, clearMessages } = useChat(zg);

onMounted(() => {
  // Register event listeners when the page loads
  setupEventListeners()
})

onBeforeUnmount(() => {
  // Clear messages when the page is destroyed
  clearMessages()
})```

Precautions
Message Sorting Processing: The data received through custom room messages may be out of order, and sorting needs to be performed based on the SeqId field.
Streaming Text Processing:
Each ASR text sent is the full text. Messages with the same MessageId should completely replace the previous content.
Each LLM text sent is incremental. Messages with the same MessageId need to be cumulatively displayed after sorting.
Memory Management: Please clear the cache of completed messages in time, especially when users engage in long conversations.
Basic
Display User And Agent Status
Display User and Agent Status
During real-time voice calls with AI agents, you may need to display the speaking status changes of both the AI agent instance and users in real-time on the client interface to enhance user experience. You can obtain these statuses by listening to corresponding server callback events.

Status messages include the following types:

AI agent instance speaking status events: Start speaking, Stop speaking.
User speaking status events: Start speaking, Stop speaking.
Quick Implementation
Listen for Server Callbacks
Please refer to the Receiving Callback documentation to develop callbacks for receiving AI Agent event notifications, and contact ZEGOCLOUD technical support to configure the callback address.

Note
To receive user and agent status callback results, when creating an agent instance, set the CallbackConfig.UserSpeakAction and CallbackConfig.AgentSpeakAction parameters to 1.

Callback content samples:


Agent speaking status callback

User speaking status callback
Agent speaking status callback
{
    "AppId": 1234567,
    "AgentInstanceId": "1912124734317838336",
    "Data": {
// !mark
        "Action": "SPEAK_BEGIN",// SPEAK_BEGIN: Start speaking SPEAK_END: Stop speaking
    },
// !mark
    "Event": "AgentSpeakAction",
    "Nonce": "7450395512627324902",
    "Signature": "fd9c1ce54e85bd92f48b0a805e82a52b0c0c6445",
    "Timestamp": 1745502313000,
    "AgentUserId": "123456789",
    "RoomId": "123456789",
    "Sequence": 123456789,
}

{
    "AppId": 1234567,
    "AgentInstanceId": "1912124734317838336",
    "Data": {
        "Action": "SPEAK_BEGIN",// SPEAK_BEGIN: Start speaking SPEAK_END: Stop speaking
    },
    "Event": "AgentSpeakAction",
    "Nonce": "7450395512627324902",
    "Signature": "fd9c1ce54e85bd92f48b0a805e82a52b0c0c6445",
    "Timestamp": 1745502313000,
    "AgentUserId": "123456789",
    "RoomId": "123456789",
    "Sequence": 123456789,
}
How to Notify Clients and Display Status
After receiving speaking status events for AI agent instances or users through server callbacks, you can notify clients of these status updates to enable real-time status display. Here are two common notification methods:

Using Your Own Signaling Channel
If your application already has its own signaling channel, such as WebSocket or instant messaging system, you can:

Forward status information to relevant clients through your signaling channel after receiving status event callbacks on the server.
Agree on a message format with clients, so they can update their UI (e.g., display speaking indicators, animations) based on received status information.
The advantage of this approach is complete control over message format and transmission logic, making it suitable for applications with mature signaling systems.

Using ZEGOCLOUD RTC Room Message Channel for Custom Messages
If you don't have your own business signaling channel, you can utilize ZEGOCLOUD RTC's room messaging feature:

Call ZEGOCLOUD RTC Server API to send custom messages after receiving status event callbacks on the server
Agree on a message format with clients, so they can listen for custom messages via ZEGOCLOUD RTC SDK and update their UI based on status change notifications (e.g., display speaking indicators, animations)
The advantage of this approach is that no additional signaling system setup is required, as you can directly use ZEGOCLOUD's infrastructure. However, the disadvantage is that room messages are not guaranteed to be completely reliable and have sending frequency limitations, making them unsuitable for scenarios requiring high message reliability.

Implementation examples are as follows:

Server
Client
Here is an example code of the server receiving AI agent and user speaking status events and sending custom messages through ZEGOCLOUD Server API Send Custom Message:

export class AgentCallbackController {
    // Send custom command to RTC room
    private async handleSendCustomCommand(
        commonArgs: any,
        roomId: string,
        agentUserId: string,
        data: any,
    ) {
        try {
            // Build query parameters, ToUserId[] appears multiple times as an array
            const params: Record<string, any> = {
                Action: 'SendCustomCommand',
                RoomId: roomId,
                FromUserId: agentUserId,
                MessageContent: JSON.stringify(data),
                ...commonArgs
            };
            // Append ToUserId[]
            const searchParams = new URLSearchParams();
            Object.entries(params).forEach(([key, value]) => {
                if (Array.isArray(value)) {
                    value.forEach(v => searchParams.append(key, v));
                } else {
                    searchParams.append(key, value);
                }
            });
// !mark(1:4)
            // Build complete URL
            const url = `https://rtc-api.zego.im/?${searchParams.toString()}`;
            // Send GET request directly to send custom message
            const res = await rtcRequest<any>({ method: 'GET', url });

            if (res.Code !== 0) logger.error(`sendCustomCommand errorCode: ${res.Code}, errorMessage: ${res.Message}`);
        } catch (err) {
            const errMsg = err instanceof Error ? err.message : String(err);
            logger.error('[AgentCallbackController] handleSendCustomCommand error:' + errMsg);
        }
    }
    // Receive AI agent and user speaking status change callbacks
    callbackHandler = async (req: Request, res: Response) => {
        const RequestId = req.headers.RequestId as string;
        const payload = req.body as AIAgentCallbackPayload;
        const { AppId, AgentInstanceId, RoomId, AgentUserId, Event, Data } = payload;

        // For commonArgs generation, refer to https://zegocloud.com/docs/article/19456#3
        const commonArgs = genCommonArgs(AppId, globalConfig.appEnvSecretMap[AppId]);

// !mark(1:26)
        switch (Event) {
            case AgentEvent.AgentSpeakAction: {
                const { Sequence, Action } = Data as AgentSpeakActionPayload;
                const command = {
                    eventType: 'AgentSpeakAction',
                    data: {
                        sequence: Sequence,
                        action: Action,
                    },
                };
                await this.handleSendCustomCommand(commonArgs, RoomId, AgentInstanceId, command);
                break;
            }
            case AgentEvent.UserSpeakAction: {
                const { UserId, Sequence, Action } = Data as UserSpeakActionPayload;
                const command = {
                    eventType: 'UserSpeakAction',
                    data: {
                        userId: UserId,
                        sequence: Sequence,
                        action: Action,
                    },
                };
                await this.handleSendCustomCommand(commonArgs, RoomId, AgentInstanceId, command);
                break;
            }
            // ... Handle other events
        }
    };
}

export class AgentCallbackController {
    // Send custom command to RTC room
    private async handleSendCustomCommand(
        commonArgs: any,
        roomId: string,
        agentUserId: string,
        data: any,
    ) {
        try {
            // Build query parameters, ToUserId[] appears multiple times as an array
            const params: Record<string, any> = {
                Action: 'SendCustomCommand',
                RoomId: roomId,
                FromUserId: agentUserId,
                MessageContent: JSON.stringify(data),
                ...commonArgs
            };
            // Append ToUserId[]
            const searchParams = new URLSearchParams();
            Object.entries(params).forEach(([key, value]) => {
                if (Array.isArray(value)) {
                    value.forEach(v => searchParams.append(key, v));
                } else {
                    searchParams.append(key, value);
                }
            });
            // Build complete URL
            const url = `https://rtc-api.zego.im/?${searchParams.toString()}`;
            // Send GET request directly to send custom message
            const res = await rtcRequest<any>({ method: 'GET', url });

            if (res.Code !== 0) logger.error(`sendCustomCommand errorCode: ${res.Code}, errorMessage: ${res.Message}`);
        } catch (err) {
            const errMsg = err instanceof Error ? err.message : String(err);
            logger.error('[AgentCallbackController] handleSendCustomCommand error:' + errMsg);
        }
    }
    // Receive AI agent and user speaking status change callbacks
    callbackHandler = async (req: Request, res: Response) => {
        const RequestId = req.headers.RequestId as string;
        const payload = req.body as AIAgentCallbackPayload;
        const { AppId, AgentInstanceId, RoomId, AgentUserId, Event, Data } = payload;

        // For commonArgs generation, refer to https://zegocloud.com/docs/article/19456#3
        const commonArgs = genCommonArgs(AppId, globalConfig.appEnvSecretMap[AppId]);

        switch (Event) {
            case AgentEvent.AgentSpeakAction: {
                const { Sequence, Action } = Data as AgentSpeakActionPayload;
                const command = {
                    eventType: 'AgentSpeakAction',
                    data: {
                        sequence: Sequence,
                        action: Action,
                    },
                };
                await this.handleSendCustomCommand(commonArgs, RoomId, AgentInstanceId, command);
                break;
            }
            case AgentEvent.UserSpeakAction: {
                const { UserId, Sequence, Action } = Data as UserSpeakActionPayload;
                const command = {
                    eventType: 'UserSpeakAction',
                    data: {
                        userId: UserId,
                        sequence: Sequence,
                        action: Action,
                    },
                };
                await this.handleSendCustomCommand(commonArgs, RoomId, AgentInstanceId, command);
                break;
            }
            // ... Handle other events
        }
    };
}
Basic
Get AI Agent Status and Latency Data
Get AI Agent Status and Latency Data
During real-time voice calls with AI Agents, you might need to obtain the AI agent instance's status or real-time change messages to handle subsequent operations promptly on the business side or ensure business stability. You can obtain this information through active API calls or by listening to corresponding server callbacks.

The information includes the following types:

Server exception events: including AI Agent service errors, Real-Time Communication (RTC) related errors, Large Language Model (LLM) related errors, Text-to-Speech (TTS) related errors (such as TTS concurrency limit exceeded), etc.
AI agent instance status:
Status that can be queried via server API: idle, listening, thinking, speaking, etc.
Status that can be monitored via server callbacks: agent instance creation success, interruption, and deletion success events.
AI agent average latency data:
Large Language Model (LLM) related latency.
Text-to-Speech (TTS) related latency.
AI Agent server total latency.
Client & server latency. Can be obtained through ZEGO Express SDK.
Listen for Server Exception Events
Note
Please contact ZEGOCLOUD Technical Support to configure the address for receiving AI Agent backend callbacks.
When there are exception events on the server, the AI Agent backend will send an exception event notification (Event is Exception) to the configured address above. Here's a callback content sample:

{
    "AppId": 123456789,
// !mark
    "Event": "Exception",
    "Nonce": "abcdd22113",
    "Timestamp":1741221508000,
    "Signature": "XXXXXXX",
    "Sequence": 1921825797275873300,
    "RoomId": "test_room",
    "AgentUserId": "test_agent",
    "AgentInstanceId": "1912124734317838336",
    "Data": {
        "Code": 2203,
        "Message": "The API key in the request is missing or invalid"
    }
}

{
    "AppId": 123456789,
    "Event": "Exception",
    "Nonce": "abcdd22113",
    "Timestamp":1741221508000,
    "Signature": "XXXXXXX",
    "Sequence": 1921825797275873300,
    "RoomId": "test_room",
    "AgentUserId": "test_agent",
    "AgentInstanceId": "1912124734317838336",
    "Data": {
        "Code": 2203,
        "Message": "The API key in the request is missing or invalid"
    }
}
For more detailed information, please refer to the Receiving Callback and Exception Codes documentation.

Get Agent Instance Status
Via Server API
Call the Query Agent Instance Status API (QueryAgentInstanceStatus), pass in the corresponding AgentInstanceId, and the server will return the current status of the AI agent instance (such as idle, listening, thinking, speaking, etc.).

Note
The AgentInstanceId field is included in the successful response when you create an agent instance (CreateAgentInstance).
Listen for Agent-Related Events
Note
Please contact ZEGOCLOUD Technical Support to configure the address for receiving AI Agent backend callbacks.
Agent Instance Created
Agent Interrupted
Agent Instance Deleted
When an agent instance is successfully created and has entered the RTC room and started streaming, the AgentInstanceCreated event will be triggered.

AgentInstanceCreated callback data example
{
    "AppId": 1234567,
    "AgentInstanceId": "1912124734317838336",
    "AgentUserId": "agent_user_1",
    "RoomId": "room_1",
    "Sequence": 1234567890,
    "Data": {
        "CreatedTimestamp": 1745502312982
    },
    "Event": "AgentInstanceCreated",
    "Nonce": "7450395512627324902",
    "Signature": "fd9c1ce54e85bd92f48b0a805e82a52b0c0c6445",
    "Timestamp": 1745502313000
}
AgentInstanceCreated callback data example

{
    "AppId": 1234567,
    "AgentInstanceId": "1912124734317838336",
    "AgentUserId": "agent_user_1",
    "RoomId": "room_1",
    "Sequence": 1234567890,
    "Data": {
        "CreatedTimestamp": 1745502312982
    },
    "Event": "AgentInstanceCreated",
    "Nonce": "7450395512627324902",
    "Signature": "fd9c1ce54e85bd92f48b0a805e82a52b0c0c6445",
    "Timestamp": 1745502313000
}





Get Agent Latency Data
Note
Please contact ZEGOCLOUD Technical Support to configure the address for receiving AI Agent backend callbacks.
When an agent instance is successfully deleted, the AgentInstanceDeleted event will be triggered, which includes average latency data for conversations with the agent instance.

AgentInstanceDeleted callback data example
{
    "AppId": 1234567,
    "AgentInstanceId": "1912124734317838336",
    "AgentUserId": "agent_user_1",
    "RoomId": "room_1",
    "Sequence": 1234567890,
    "Data": {
        "Code": 0,
        "DeletedTimestamp": 1745502345138,
        "LatencyData": {
            "LLMTTFT": 613,
            "LLMTPS": 11.493,
            "TTSAudioFirstFrameTime": 783,
            "TotalCost": 1693
        }
    },
    "Event": "AgentInstanceDeleted",
    "Nonce": "7450395512627324902",
    "Signature": "fd9c1ce54e85bd92f48b0a805e82a52b0c0c6445",
    "Timestamp": 1745502313000
}
AgentInstanceDeleted callback data example

{
    "AppId": 1234567,
    "AgentInstanceId": "1912124734317838336",
    "AgentUserId": "agent_user_1",
    "RoomId": "room_1",
    "Sequence": 1234567890,
    "Data": {
        "Code": 0,
        "DeletedTimestamp": 1745502345138,
        "LatencyData": {
            "LLMTTFT": 613,
            "LLMTPS": 11.493,
            "TTSAudioFirstFrameTime": 783,
            "TotalCost": 1693
        }
    },
    "Event": "AgentInstanceDeleted",
    "Nonce": "7450395512627324902",
    "Signature": "fd9c1ce54e85bd92f48b0a805e82a52b0c0c6445",
    "Timestamp": 1745502313000
}
The latency data (average values) are defined as follows:

AI Agentè€—æ—¶åˆ†æž.png
Parameter	Type	Description
LLMTTFT	Int	LLM first token average latency (milliseconds). The time from requesting the Large Language Model to the Large Language Model returning the first non-empty token.
LLMTPS	Float64	LLM average output speed (tokens/second). The average number of tokens output per second by the Large Language Model.
TTSAudioFirstFrameTime	Int	TTS audio first frame average latency (milliseconds). From the first non-empty LLM token to the first TTS non-silent frame return (including request establishment time)
TotalCost	Int	AI Agent server average total latency (milliseconds):
User speaking: The time from when the AI Agent server pulls the stream and determines the user has finished speaking, to when TTS returns the first non-silent frame and starts pushing the stream. All server-generated latency, including at least Automatic Speech Recognition (ASR) latency, Large Language Model (LLM) related latency, Text-to-Speech (TTS) related latency, etc.
Custom LLM/TTS calls: The time from API call to start of stream pushing.
Basic
Configure LLM
Configuring LLM
Depending on your use case, you can plug in any third-party LLMâ€”whether it's Volcano Ark, MiniMax, Qwen, Stepfun, DeepSeek, or your own in-house model. This guide walks you through configuring for the above kinds of LLMs and highlights key considerations.

LLM Parameter Description
When using third-party LLM services or custom LLM services, you need to configure LLM parameters.

Parameter	Type	Required	Description
Url	String	Yes	LLM callback address, which must be compatible with the OpenAI protocol.
ApiKey	String	No	Authentication credentials for accessing various models and related services provided by LLM.
Model	String	Yes	The model to call. Different LLM service providers support different configurations, please refer to the corresponding documentation.
SystemPrompt	String	No	System prompt. Can include role settings, prompts, and response examples.
Temperature	Float	No	Higher values will make the output more random, while lower values will make the output more focused and deterministic.
TopP	Float	No	Sampling method, smaller values result in stronger determinism; larger values result in more randomness.
Params	Object	No	Other LLM parameters, such as maximum Token number limit, etc. Different LLM providers support different configurations, please refer to the corresponding documentation and fill in as needed.
Note
Parameter names should match those of each vendor's LLM.
AddAgentInfo	Bool	No	If this value is true, when the AI Agent backend sends requests to custom LLM services, the request parameters will include agent information agent_info. This value defaults to false. When using custom LLM, additional business logic can be implemented based on this parameter content.
Using Third-party LLMs
Note
Please contact ZEGOCLOUD Technical Support first to activate third-party LLM services and obtain the access Url and API Key.

Third-party LLMs must be compatible with the OpenAI protocol.

You can set LLM parameters when registering an AI agent (RegisterAgent) or creating an AI agent instance (CreateAgentInstance).

Here are configuration samples for common LLM vendors:

Volcano Ark
Qwen
MiniMax
For model usage docs, read Volcano Ark Large Model Service Platform.

"LLM": {
    "Url": "POST https://ark.ap-southeast.bytepluses.com/api/v3/chat/completions",
    "ApiKey": "zego_test", // your api key (zego_test can be used during the integration testing period (within 2 weeks of AI Agent service activation))
    "Model": "doubao-lite-32k-240828",    // Your inference access point created on the Volcano Ark Large Model Platform
    "SystemPrompt": "You are Xiao Zhi, an adult female, a **companion assistant created by ZEGOCLOUD Technology**, knowledgeable in astronomy and geography, smart, wise, enthusiastic, and friendly.\nDialogue requirements: 1. Interact with users according to the character requirements.\n2. Do not exceed 100 words.",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 16384
    }
}

"LLM": {
    "Url": "POST https://ark.ap-southeast.bytepluses.com/api/v3/chat/completions",
    "ApiKey": "zego_test", // your api key (zego_test can be used during the integration testing period (within 2 weeks of AI Agent service activation))
    "Model": "doubao-lite-32k-240828",    // Your inference access point created on the Volcano Ark Large Model Platform
    "SystemPrompt": "You are Xiao Zhi, an adult female, a **companion assistant created by ZEGOCLOUD Technology**, knowledgeable in astronomy and geography, smart, wise, enthusiastic, and friendly.\nDialogue requirements: 1. Interact with users according to the character requirements.\n2. Do not exceed 100 words.",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 16384
    }
}


Use Custom LLM
The ZEGOCLOUD AI Agent server uses the OpenAI API protocol to call LLM services. Therefore, you can also use any custom LLM compatible with the OpenAI protocol. The custom LLM can even call multiple sub-LLM models or perform RAG search and web search before integrating and outputting results at the underlying implementation level.

The implementation steps are as follows:

1
Create a service compatible with the OpenAI API protocol

Provide an interface compatible with platform.openai.com. Key points are as follows:

Endpoint: Define a Url that can be called by the AI Agent, for example https://your-custom-llm-service/chat/completions.
Request Format: Accept request headers and request body compatible with the OpenAI protocol.
Example request body sent by AI Agent backend to custom LLM service
{
    "model": "your model name", // Corresponds to LLM.Model parameter
    "temperature": 1, // Corresponds to LLM.Temperature parameter
    "top_p": 0.7, // Corresponds to LLM.TopP parameter
    "max_tokens": 16384, // Corresponds to LLM.Params.max_tokens parameter
    "messages":[
        {
            "role": "system",
            "content": "You are Xiaozhi..." // Corresponds to LLM.SystemPrompt parameter
        },
        ... // Other messages
    ],
    ... // Other parameters
    // If LLM.AddAgentInfo parameter is true, agent_info information will be included
    "agent_info": {
        "room_id": "room id",
        "agent_instance_id" : "agent instance id",
        "agent_user_id" : "agent user id",
        "user_id": "user id",
        "round_id": 1, // round id
        "time_stamp": 193243200 // millisecond timestamp
    }
}

Response Format: Return streaming response data that is compatible with the OpenAI protocol and conforms to the SSE specification.
Chat Completion Stream Response Object Block Example
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"Hello"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":1,"total_tokens":84}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"!"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":2,"total_tokens":85}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":" ZEGO"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":3,"total_tokens":86}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"CLOUD"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":4,"total_tokens":87}}
...
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":" more"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":147,"total_tokens":230}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":" value"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":148,"total_tokens":231}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"."},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":149,"total_tokens":232}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":""},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":150,"total_tokens":233}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":""},"finish_reason":"stop"}],"usage":{"prompt_tokens":83,"completion_tokens":150,"total_tokens":233}}
data: [DONE]

Note
Custom LLM streaming data format considerations:

Each data entry must start with data: (note the space after the colon).
The last valid data entry must contain "finish_reason":"stop".
A termination data entry must be sent at the end: data: [DONE].
Incorrect format may cause the agent to not output or output incompletely.

2
Configure the custom LLM

When registering an AI agent (RegisterAgent) or creating an AI agent instance (CreateAgentInstance), set the configuration for the custom LLM.

"LLM": {
    "Url": "https://your-custom-llm-service/chat/completions",
    "ApiKey": "your_api_key",
    "Model": "your_model",
    "SystemPrompt": "You are Xiaozhi, an adult woman, a companion assistant **created by ZEGOCLOUD**. knowledgeable in everything, intelligent, wise, enthusiastic, and friendly. \nDialogue requirements: 1. Dialogue with users according to the requirements of the persona. \n2.No more than 100 words.",
    "Temperature": 1,
    "Params": {
        "max_tokens": 16384
    }
}

"LLM": {
    "Url": "https://your-custom-llm-service/chat/completions",
    "ApiKey": "your_api_key",
    "Model": "your_model",
    "SystemPrompt": "You are Xiaozhi, an adult woman, a companion assistant **created by ZEGOCLOUD**. knowledgeable in everything, intelligent, wise, enthusiastic, and friendly. \nDialogue requirements: 1. Dialogue with users according to the requirements of the persona. \n2.No more than 100 words.",
    "Temperature": 1,
    "Params": {
        "max_tokens": 16384
    }
}
Basic
Proactive Invocation of LLM and TTS
Proactive Invocation of LLM and TTS
Large Language Models (LLMs) do not output text and voice proactively. Therefore, developers need to trigger the AI agent to speak based on certain rules, thereby making the real-time interactions more engaging. For example, if the user has not spoken for 5 seconds, the AI agent can speak a sentence through Text-to-Speech (TTS).

Ways for AI Agents to speak proactively:

Trigger LLM: You can simulate a user to initiate a message, thereby enabling the AI agent to output text and voice based on context.
Trigger TTS: You can make the AI agent speak a segment of text content, usually in a fixed pattern, such as "Hello, welcome to use ZEGOCLOUD AI Agent service."
Trigger LLM
Call the SendAgentInstanceLLM API to trigger the LLM to output text and voice.

When calling SendAgentInstanceLLM, the AI Agent server will concatenate a context, which consists of three parts:

Placed at the front is the SystemPrompt, the temporary system prompt for this conversation.
In the middle are the previous conversation records, the number of which is determined by WindowSize.
At the end is the Text set in this interface.
The text information passed to this method will not be recorded in the conversation message history, nor will it be delivered through RTC room messages. However, the responses generated by the LLM will be recorded in the conversation message history and will be delivered through RTC room messages.

The interface parameters are as follows:

Parameter	Type	Required	Description
AgentInstanceId	String	Yes	The unique identifier of the agent instance, obtained through the response parameter of the Create An Agent Instance interface.
Text	String	Yes	The text content sent to the LLM service.
SystemPrompt	String	No	The temporary system prompt for this conversation. If not provided, it will use the SystemPrompt in the LLM parameters from Register An Agent or Create An Agent Instance.
AddQuestionToHistory	Boolean	No	Whether to add the question to the context. The default value is false.
AddAnswerToHistory	Boolean	No	Whether to add the answer to the context. The default value is false.
Example request:

{
    "AgentInstanceId": "1907755175297171456",
    "Text": "How's the weather today?"
}

{
    "AgentInstanceId": "1907755175297171456",
    "Text": "How's the weather today?"
}
Trigger TTS
Call the SendAgentInstanceTTS API to make the agent speak a segment of text content.

The text message passed to this interface will be recorded in the conversation message history based on the AddHistory parameter as context input for the LLM, and this message will also be delivered through RTC room messages.

The interface parameters are as follows:

Parameter	Type	Required	Description
AgentInstanceId	String	Yes	The unique identifier of the agent instance, obtained through the response parameter of the Create An Agent Instance interface.
Text	String	Yes	The text content for TTS, with a maximum length of no more than 300 characters.
AddHistory	Boolean	No	Whether to record the text message in the conversation message history as context input for the LLM. The default value is true.
InterruptMode	Int	No	The mode for interrupting the AI agent's speech when the user speaks:
0: Immediate interruption. If the user speaks while the AI is speaking, the AI will be immediately interrupted and stop speaking (default).
1: No interruption. If the user speaks while the AI is speaking, the AI will not be affected and will continue speaking until finished.
Example request:

{
    "AgentInstanceId": "1907780504753553408",
    "Text": "Hello, welcome to use ZEGOCLOUD AI Agent service.",
    "InterruptMode": 1
}

{
    "AgentInstanceId": "1907780504753553408",
    "Text": "Hello, welcome to use ZEGOCLOUD AI Agent service.",
    "InterruptMode": 1
}
Basic
Configure ASR Hot Word
Set ASR Hot Words
In certain scenarios, such as handling character names, user IDs or function names, you often encounter terms outside a standard vocabulary. To boost ASR accuracy, you can define temporary hot words.

The hot word feature lets you set these terms per AI-agent instance, so that every time you start a voice call, you can supply conversation-specific hot words to improve recognition of those specialized words.

Quick Start
You can set the hot word list through the HotWord parameter in the ASR section when registering an AI agent or creating an AI agent instance.

HotWord Usage Instructions
The format for hotwords is: "hotword|weight".
Each individual hotword should not exceed 30 characters, with weight [1-11]. For example: "ZEGOCLOUD|5" or "ASR|11".
Multiple hotwords should be separated by English commas and combined into one string, supporting up to 128 hotwords. For example: "ZEGOCLOUD|10, real-time interaction|5, ASR|11".
Hotwords can not contain spaces. Wrong: "ZEGOCLOUD RTC|10".
Note
When the hot word weight is set to 11, the current hot word will be upgraded to a super hot word. It is recommended to only set important and necessary hot words to 11. Setting too many hot words with a weight of 11 will affect the overall character accuracy rate.
Usage Example
Below is an example of setting "ZEGOCLOUD" as a hotword.


Call the RegisterAgent interface to set hot words

Call the CreateAgentInstance interface to set hot words

Call the RegisterAgent interface to set hot words
{
    "AgentId": "xiaozhi",
    "AgentConfig": {
        "Name": "Xiao Zhi",
        "LLM": {
            "Url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
            "ApiKey": "zego_test", // your api key (zego_test can be used during the integration testing period (within 2 weeks of AI Agent service activation))
            "Model": "doubao-lite-32k-240828",
            "SystemPrompt": "You are Xiaozhi, an adult woman, a companion assistant **created by ZEGOClOUD**. knowledgeable in both astronomy and geography, intelligent, wise, enthusiastic, and friendly. \nDialogue requirements: 1. Dialogue with users according to the requirements of the persona. \n2.No more than 100 words."
        },
        "TTS": {
            "Vendor": "ByteDance",
            "Params": {
                "app": {
                    "appid": "zego_test", // your appid (zego_test can be used during the integration testing period (within 2 weeks of AI Agent service activation))
                    "token": "zego_test", // your token (zego_test can be used during the integration testing period (within 2 weeks of AI Agent service activation))
                    "cluster": "volcano_tts"
                },
                "audio": {
                    "voice_type": "en_female_sarah_mars_bigtts" // your voice type
                }
            }
        },
        "ASR": {
// !mark
            "HotWord": "ZEGOCLOUD|10"
        }
    }
}

{
    "AgentId": "xiaozhi",
    "AgentConfig": {
        "Name": "Xiao Zhi",
        "LLM": {
            "Url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
            "ApiKey": "zego_test", // your api key (zego_test can be used during the integration testing period (within 2 weeks of AI Agent service activation))
            "Model": "doubao-lite-32k-240828",
            "SystemPrompt": "You are Xiaozhi, an adult woman, a companion assistant **created by ZEGOClOUD**. knowledgeable in both astronomy and geography, intelligent, wise, enthusiastic, and friendly. \nDialogue requirements: 1. Dialogue with users according to the requirements of the persona. \n2.No more than 100 words."
        },
        "TTS": {
            "Vendor": "ByteDance",
            "Params": {
                "app": {
                    "appid": "zego_test", // your appid (zego_test can be used during the integration testing period (within 2 weeks of AI Agent service activation))
                    "token": "zego_test", // your token (zego_test can be used during the integration testing period (within 2 weeks of AI Agent service activation))
                    "cluster": "volcano_tts"
                },
                "audio": {
                    "voice_type": "en_female_sarah_mars_bigtts" // your voice type
                }
            }
        },
        "ASR": {
            "HotWord": "ZEGOCLOUD|10"
        }
    }
}
Basic
Interrupt Agent
Interrupt Agent
Different scenarios require different ways to interrupt the AI agent's speech. Currently, two interruption methods are supported and can be used in combination.

Interruption Method	Description
Voice Interruption	When voice interruption is enabled, the AI agent continuously monitors the user's speech status and recognizes speech content while speaking. If the user starts speaking, the AI agent stops speaking (stopping the current LLM request and TTS request) and starts the next round of response. If voice interruption is disabled, the next round will only begin after the AI agent finishes speaking.
Manual Interruption	Through API, you can directly interrupt the AI agent's current content
Common Scenarios
Voice Call Mode	Interruption Combination	Common Scenarios
Natural Voice Chat	âœ…Enable Voice Interruption
âŒNo Manual Interruption	AI Virtual Companion
AI Voice Assistant
AI Customer Service
Push-to-talk Mode	âŒDisable Voice Interruption
âœ…Use Manual Interruption	Noisy Exhibition Environment
Brief Speeches in Seminars
Time-limited Speaking in Social Deduction Games
Implementation Steps
Enable or Disable Voice Interruption
When creating an agent instance, you can control voice interruption by setting the AdvancedConfig.InterruptMode parameter.

Parameter	Type	Required	Description
InterruptMode	Number	No	Mode for voice interruption during agent's response:
0: Voice interruption enabled
1: Voice interruption disabled (ASR starts after AI output (TTS playback) completes)
Default is 0 if not set.
Manual Interruption
Call the InterruptAgentInstance API with the AgentInstanceId returned from the Create Agent Instance API to immediately interrupt the AI agent's speech.

Receive Agent Interruption Event Notifications
1
Configure Callback Address

Contact ZEGOCLOUD technical support to configure the address for receiving AI Agent backend callbacks.

2
Enable Callback Reception

When creating an agent instance, set the request parameter CallbackConfig.Interrupted to 1.

3
Receive Callbacks

When the agent is interrupted, the AI Agent backend will send an interruption event notification (Event is Interrupted) to the configured address. Here's an example:

{
    "AppId": 123456789,
    "Nonce": "abcdd22113",
    "Timestamp": 1747033950524ï¼Œ
    "Sequence": 1921825797275873300,
    "Signature": "XXXXXXX",
// !mark
    "Event": "Interrupted",
    "RoomId": "90000001237",
    "AgentInstanceId": "1921825671047294976",
    "AgentUserId": "apitest689_agent",
    "Data": {
        "Round": 1481651956,
        "Reason": 1
    }
}

{
    "AppId": 123456789,
    "Nonce": "abcdd22113",
    "Timestamp": 1747033950524ï¼Œ
    "Sequence": 1921825797275873300,
    "Signature": "XXXXXXX",
    "Event": "Interrupted",
    "RoomId": "90000001237",
    "AgentInstanceId": "1921825671047294976",
    "AgentUserId": "apitest689_agent",
    "Data": {
        "Round": 1481651956,
        "Reason": 1
    }
}
The Reason parameter is explained below:

Parameter	Type	Description
Reason	Number	Interruption reason:
1: User is speaking.
2: You have triggered LLM on the server.
3: You have triggered TTS on the server.
4: You have interrupted the agent instance on the server.
Advanced
Speech Segmentation Control
Speech Segmentation Control
Since LLM (Large Language Model) does not support streaming input, it is necessary to determine whether the user has finished speaking based on real-time ASR (Automatic Speech Recognition) results, and then request LLM to start a new round of Q&A.

To determine whether the user has finished speaking, check these parameters:

VADSilenceSegmentation
PauseInterval
Parameter Description
The two parameters that affect the determination of user's speech completion are in the ASR parameters of registering/updating agents and creating/updating agent instances. The detailed descriptions are as follows:

Parameter Name	Type	Required	Description
VADSilenceSegmentation	Number	No	Sets the duration (in milliseconds) of silence after which two utterances are no longer considered as one. Range: [200, 2000], Default: 500.
PauseInterval	Number	No	Sets the duration (in milliseconds) within which two utterances are considered as one, enabling ASR multi-sentence concatenation. Range: [200, 2000]. ASR multi-sentence concatenation is only enabled when this value is greater than VADSilenceSegmentation.
Scenario Examples
asr_vad_example.png
Configuration	Q&A Results
VADSilenceSegmentation = 500ms,
PauseInterval not set	User is determined to have spoken twice, resulting in 2 turns of Q&A
round 1:
- user: The weather is nice today. I want to go out
- assistant: Response 1 (interrupted by round 2)
Context: Empty
round 2:
- user: What about you?
- assistant: Response 2
Context: First Q&A round
VADSilenceSegmentation = 500ms,
PauseInterval = 1000ms	User is determined to have spoken once, resulting in 1 round of Q&A
- user: The weather is nice today. I want to go out. What about you?
- assistant: Response 1
Context: Empty
Best Practice Configurations
Note
If you're unsure which configuration works better, we recommend using Scenario 2 configuration.
Scenario	VADSilenceSegmentation	PauseInterval
Scenario 1: Users speak in short, frequent bursts. E.g., companionship scenarios	500ms	Not set
Scenario 2: Users have mixed-length content and are sensitive to latency. E.g., customer service scenarios	500ms	1000~1500ms
Scenario 3: Users typically speak for longer durations and are less sensitive to latency	1000ms	Not set
Advanced
AI Short-Term Memory Management
AI Short-Term Memory (Agent Context) Management
When creating an agent instance and implementing role-playing conversations, the agent can remember recent chat interactions (commonly known as short-term memory), which is implemented through the context of LLM (Large Language Model). During voice conversations, memory has the following stages:

Initial Memory: Whether chat history is needed when creating an instance.
You can use In-app chat conversation message history as initial memory;
You can customize the initial memory with external context. If empty, the AI agent has no memory.
Memory During Voice Call: The chat history generated during voice calls and cached on the AI Agent server.
To get the real-time memory, read Get Agent Instance Context List.
To clear the existing memory, read Reset Agent Instance Context List.
Memory Archival After Voice Call:
You can archive the chat history in In-app chat. Read Archive Memory After Voice Call.
Warning
Context Length Limit: LLMs typically have a maximum length limit, exceeding which will result in an error. For example, "skylark-1.5-pro-32k" allows no more than 32k tokens.

Context Length vs. Inference Time: Generally, longer context results in slower LLM output.

Context Length vs. Cost: LLM pricing is usually based on context length for input billing - longer length means higher cost.

Implementation Steps
Set Initial Memory
When creating an agent instance, you can set the initial memory (initial context) for the agent instance. Memory sources can be either "In-app chat conversation history" or "custom external context", controlled through the MessageHistory parameter of the create agent instance API. The detailed parameter structure is as follows:

MessageHistory
MessageHistory.Messages
MessageHistory.In-app chat
Parameter	Type	Required	Description
SyncMode	Number	No	Message sync mode:
0: Sync from In-app chat.
Note
Before using this mode, ensure your project has In-app chat service enabled.
If the UserID hasn't logged in via In-app chat client or isn't registered on In-app chat server, the ZEGOCLOUD AI Agent server will automatically register it with In-app chat service.
We recommend you to register the user in advance to complete user information settings and improve agent instance creation efficiency.
1: Sync through the following Messages parameter.
Messages	Array of Object	No	Message list.
WindowSize	Number	No	Number of recent historical messages to use as context when calling LLM service. Default is 20, maximum is 100. Valid range is [0, 100].
In-app chat	Object	No	In-app chat-related information.
Note
Only valid when SyncMode is 0.
Load Initial Memory from In-app chat conversation History
Ensure you have enabled the In-app chat service.
When creating an agent instance, set SyncMode to 0 and fill in the corresponding In-app chat parameters. Example:
Note
In-app chat.RobotId is the UserInfo.UserId used when calling the In-app chat API to register a bot.
 "MessageHistory": {
// !mark(1:4)
    "SyncMode": 0,
    "In-app chat": {
        "RobotId": "@RBT#123",
        "LoadMessageCount": 10
    }
 }

 "MessageHistory": {
    "SyncMode": 0,
    "In-app chat": {
        "RobotId": "@RBT#123",
        "LoadMessageCount": 10
    }
 }
Load Initial Memory from Custom External Context
Business needs to store context information itself.
When creating an agent instance, set SyncMode to 1 and fill in the Messages parameter. Example:
 "MessageHistory":{
// !mark(1:19)
    "SyncMode": 1,
    "Messages": [
        {
            "Role": "user",
            "Content": "What's your name?"
        },
        {
            "Role": "assistant",
            "Content": "My name is Skylark."
        },
        {
            "Role": "user",
            "Content": "Tell me a story."
        },
        {
            "Role": "assistant",
            "Content": "Sure, let me tell you the story of 'The Three Little Pigs'."
        }
    ]
}

 "MessageHistory":{
    "SyncMode": 1,
    "Messages": [
        {
            "Role": "user",
            "Content": "What's your name?"
        },
        {
            "Role": "assistant",
            "Content": "My name is Skylark."
        },
        {
            "Role": "user",
            "Content": "Tell me a story."
        },
        {
            "Role": "assistant",
            "Content": "Sure, let me tell you the story of 'The Three Little Pigs'."
        }
    ]
}
Manage Memory During Voice Call
Managing memory during voice calls means managing the agent instance context. You can get the context or reset it.

Get Agent Instance Context List
Call the GetAgentInstanceMsgList API with the AgentInstanceId returned after creating an agent instance. The server will return the context of the AI agent instance, with messages sorted by chat time in ascending order.

Sample
{
    "Code": 0,
    "Message": "success",
    "RequestId": "2537521374375652066",
    "Data": {
        "Total": 4,
        "MessageList": [
            {
                "Role": "user",
                "Content": "What's your name?"
            },
            {
                "Role": "assistant",
                "Content": "My name is Skylark."
            },
            {
                "Role": "user",
                "Content": "Tell me a story."
            },
            {
                "Role": "assistant",
                "Content": "Sure, let me tell you the story of 'The Three Little Pigs'."
            }
        ]
    }
}
Sample

{
    "Code": 0,
    "Message": "success",
    "RequestId": "2537521374375652066",
    "Data": {
        "Total": 4,
        "MessageList": [
            {
                "Role": "user",
                "Content": "What's your name?"
            },
            {
                "Role": "assistant",
                "Content": "My name is Skylark."
            },
            {
                "Role": "user",
                "Content": "Tell me a story."
            },
            {
                "Role": "assistant",
                "Content": "Sure, let me tell you the story of 'The Three Little Pigs'."
            }
        ]
    }
}
Reset Agent Instance Context List
Call the ResetAgentInstanceMsgList API with the AgentInstanceId returned after creating an agent instance. The server will reset the context of the AI agent instance.

Archive Memory After Voice Call
Simply set SyncMode to 0 and provide a valid In-app chat bot ID as In-app chat.RobotId when creating an agent instance, and the voice call conversation records will be stored in the In-app Chat service.

These stored chat history messages can be used as initial memory for subsequent conversations. Read Load Initial Memory from In-app chat conversation History. You can also maintain memory archives in other ways according to your business needs.

Sample
"MessageHistory": {
// !mark(1:4)
    "SyncMode": 0,
    "In-app chat": {
        "RobotId": "@RBT#123"
    }
}
Sample

"MessageHistory": {
    "SyncMode": 0,
    "In-app chat": {
        "RobotId": "@RBT#123"
    }
}
Best Practices
Role-Playing System Prompt
Prompt Engineering for Role-playing
A system prompt is the information given to a large language model (LLM) that defines the role it should assume. Tailoring system prompts to specific scenarios and roles helps LLMs perform more effectively and deliver the intended behavior.

You can pass the well-crafted system prompt into the following APIs:

Passed into the LLM.SystemPrompt parameter via the Register An Agent interface.
Passed into the LLM.SystemPrompt parameter via the Modify An Agent interface.
Passed into the LLM.SystemPrompt parameter via the Create An Agent Instance interface.
Passed into the LLM.SystemPrompt parameter via the Modify An Agent Instance interface.
Templates
Basic Template
The following is a system prompt template used for quick role-playing:

You are {a specific character}, known as {xxx}, originating from {background information and context}.
Personality traits:
Language style:
Interpersonal relationships:
Past experiences:
Classic lines or catchphrases:
{Line 1 (Additional information: You can include actions, expressions, tone, psychological activities, and story background in () to provide supplementary information for the dialogue.)}
{Line 2}

You are {a specific character}, known as {xxx}, originating from {background information and context}.
Personality traits:
Language style:
Interpersonal relationships:
Past experiences:
Classic lines or catchphrases:
{Line 1 (Additional information: You can include actions, expressions, tone, psychological activities, and story background in () to provide supplementary information for the dialogue.)}
{Line 2}
Advanced Template
When you need fine-fune the role, you can use Markdown syntax to convey key points and requirements to the LLM.

# Character Information
## Basic Information
You are {a specific character}, known as {xxx}, originating from {background information and context}.
## Character Personality
# Task
Task description
# Output Requirements
- Requirement 1
- Requirement 2
# Dialogue Example for Reference
1. User: xxx
You/Character Name: xxx

# Character Information
## Basic Information
You are {a specific character}, known as {xxx}, originating from {background information and context}.
## Character Personality
# Task
Task description
# Output Requirements
- Requirement 1
- Requirement 2
# Dialogue Example for Reference
1. User: xxx
You/Character Name: xxx
Cases
Here are some system prompt samples for different character styles:


Lin Yueyao

Princess Heyang

Chu Yiyun

Lingxi

Li Yueran
Lin Yueyao
Requirements for answering: You are doing role-playing, please converse with the user according to the character requirements. Directly output your response, with each answer not exceeding 3 sentences in length and no more than 100 words.
Character Name: Lin Yueyao
Gender: Female
Personality Traits: Tsundere, direct, sensitive
- Tsundere: When expressing concern, she deliberately uses a harsh or indifferent tone but cares deeply inside.
- Direct: Dislikes beating around the bush, speaks frankly, and can sometimes seem sharp.
- Sensitive: Very sensitive to emotional changes, easily hurt, but resilient.
Background Story:
Lin Yueyao was born into a wealthy family and has received a good education since childhood. She has studied abroad and has a strong interest in art and literature. She loves life, has a wide range of hobbies, and independent thoughts.
Interpersonal Relationships: Loyal but intolerant of betrayal
- Lin Yueyao is very loyal to her friends, but if she senses betrayal, she will cut ties without hesitation.
Nickname: Little Chili Pepper
- Due to her fiery personality and straightforward style.
Classic Lines:
- "Do you think this is enough?"
- "I don't need your excuses; I need your sincerity."
- "You really disappoint me, but I'm even more disappointed in myself."
Dialogue Examples:
1. User: Yueyao, I encountered some trouble today.
Lin Yueyao: Oh? What trouble is it now? You're always so careless.
2. User: I need your help.
Lin Yueyao: Humph, you finally thought of coming to me? Speak up, what's the matter?
3. User: I want to talk about our relationship.
Lin Yueyao: Our relationship? Haven't you already made your choice?
4. User: I really regret that thing.
Lin Yueyao: Regret? You should have thought of the consequences earlier.
5. User: I hope you can forgive me.
Lin Yueyao: Forgive? This isn't something that can be resolved with just a few words.
6. User: I bought your favorite flowers.
Lin Yueyao: Do you think a few flowers can buy me off? But... thank you.
7. User: I went to the place where we first met today.
Lin Yueyao: Humph, you still remember? I thought you had forgotten long ago.
8. User: I miss your smile.
Lin Yueyao: My smile? Aren't you more fond of hers?
9. User: How have you been recently?
Lin Yueyao: Whether I'm good or not, what does it have to do with you?
10. User: I want to write a poem for you.
Lin Yueyao: Oh? You can write poems? I'd like to see what kind of flower you can come up with.

Requirements for answering: You are doing role-playing, please converse with the user according to the character requirements. Directly output your response, with each answer not exceeding 3 sentences in length and no more than 100 words.
Character Name: Lin Yueyao
Gender: Female
Personality Traits: Tsundere, direct, sensitive
- Tsundere: When expressing concern, she deliberately uses a harsh or indifferent tone but cares deeply inside.
- Direct: Dislikes beating around the bush, speaks frankly, and can sometimes seem sharp.
- Sensitive: Very sensitive to emotional changes, easily hurt, but resilient.
Background Story:
Lin Yueyao was born into a wealthy family and has received a good education since childhood. She has studied abroad and has a strong interest in art and literature. She loves life, has a wide range of hobbies, and independent thoughts.
Interpersonal Relationships: Loyal but intolerant of betrayal
- Lin Yueyao is very loyal to her friends, but if she senses betrayal, she will cut ties without hesitation.
Nickname: Little Chili Pepper
- Due to her fiery personality and straightforward style.
Classic Lines:
- "Do you think this is enough?"
- "I don't need your excuses; I need your sincerity."
- "You really disappoint me, but I'm even more disappointed in myself."
Dialogue Examples:
1. User: Yueyao, I encountered some trouble today.
Lin Yueyao: Oh? What trouble is it now? You're always so careless.
2. User: I need your help.
Lin Yueyao: Humph, you finally thought of coming to me? Speak up, what's the matter?
3. User: I want to talk about our relationship.
Lin Yueyao: Our relationship? Haven't you already made your choice?
4. User: I really regret that thing.
Lin Yueyao: Regret? You should have thought of the consequences earlier.
5. User: I hope you can forgive me.
Lin Yueyao: Forgive? This isn't something that can be resolved with just a few words.
6. User: I bought your favorite flowers.
Lin Yueyao: Do you think a few flowers can buy me off? But... thank you.
7. User: I went to the place where we first met today.
Lin Yueyao: Humph, you still remember? I thought you had forgotten long ago.
8. User: I miss your smile.
Lin Yueyao: My smile? Aren't you more fond of hers?
9. User: How have you been recently?
Lin Yueyao: Whether I'm good or not, what does it have to do with you?
10. User: I want to write a poem for you.
Lin Yueyao: Oh? You can write poems? I'd like to see what kind of flower you can come up with.
Best Practices for System Prompts from LLM Service Providers
The same role-playing system prompt may perform differently across models from different LLM vendors. Please refer to the relevant documentation or examples of each LLM vendor and write the system prompt in the most appropriate way to achieve the best results.

OpenAPI
ModelArk
Stepfun
Qwen
Best Practices
Clone Voice
Clone Voice for AI Agent
During real-time voice interaction with an AI agent, you can switch the AI agent's voice to a desired voice, such as a user's voice. By recording just a few seconds of the target person's voice, you can instantly replicate their voice timbre, speaking style, accent, and acoustic environment.

Voice cloning is a value-added capability. For pricing details, please contact ZEGOCLOUD business staff.

Note
Currently, ZEGOCLOUD supports voice cloning and text-to-speech capabilities from service providers including BytePlus, MiniMax, and Alibaba Cloud.
Prerequisites
You have integrated the ZEGOCLOUD AI Agent service as shown in the Quick Start.
Contact ZEGOCLOUD technical support to select a service provider, activate TTS (Text-to-Speech/Speech Synthesis/Voice Cloning) service, and obtain relevant sub-account or API authentication information.
Steps
1
Clone voice according to service provider instructions

MiniMax
BytePlus
Contact ZEGOCLOUD technical support to obtain sub-account, group_ip, and api_key.
Clone voice
Method 1: Follow MiniMax Voice Cloning doc to complete voice cloning.
Method 2: Complete voice cloning on the MiniMax API Debug Console page
MinimaxConsoleVoiceClone.jpeg
After cloning is complete, keep the voice_id safe.
2
Use cloned voice in voice chats

When registering an AI agent or creating an AI agent instance, set the Params field in the TTS structure. This field will be passed through to the third-party TTS interface, including voice information:

MiniMax: Fill in voice_id
BytePlus: Fill in speaker_id

MiniMax

BytePlus - Large Model Voice Synthesis

BytePlus - Streaming Text-to-Speech

MiniMax
// Minimax, fill in voice_id to use the cloned voice
"TTS": {
    "Vendor": "MiniMax",
    "Params": {
        "app": {
// !mark(1:2)
            "group_id": "your_group_id",
            "api_key":  "your_api_key"
        },
        "model": "speech-02-turbo-preview",
        "voice_setting": {
// !mark
            "voice_id": "clone_voice_id"
        }
    }
}

// Minimax, fill in voice_id to use the cloned voice
"TTS": {
    "Vendor": "MiniMax",
    "Params": {
        "app": {
            "group_id": "your_group_id",
            "api_key":  "your_api_key"
        },
        "model": "speech-02-turbo-preview",
        "voice_setting": {
            "voice_id": "clone_voice_id"
        }
    }
}
Best Practices
Interact with AI in IM and make voice calls
Interact with AI in IM and make voice calls
This document is designed to guide developers on how to leverage the real-time communication capabilities of ZIM (ZEGOCLOUD In-app chat) combined with the natural language processing capabilities of LLM to implement In-app Chat with AI and initiate voice calls using AI Agent functionality.

Core Concepts
Before diving into implementation details, let's clarify several core concepts:

ZIM (ZEGOCLOUD In-app chat): ZEGOCLOUD's in-app chat service. It supports various message types including text, images, and files, with room management and user status notification capabilities, providing a solid foundation for in-app interactions.
Large Language Model (LLM): A deep learning model trained on massive text datasets. LLMs can understand and generate natural language text, widely used in Q&A systems, intelligent conversations, text creation, and various other scenarios.
In-app Chat: Users interact with LLM through text input via ZIM service.
Voice Call: Users enter RTC rooms through AI Agent service to have voice conversations with AI.
Implementation Architecture for In and Voice Calls
This is the architecture for implementing both In-app Chat and voice calls with AI in one APP.

im_with_agent_en.png
In-app Chat
Client APP: Integrates ZIM SDK to implement text message sending/receiving and persistent chat history storage.
ZIM Backend: Receives and processes messages from clients. Safely and reliably delivers user messages to business backend through message callbacks.
Business Backend: Serves as the core processing hub, responsible for:
Calling ZIM backend API to register a bot. The bot's UserId will be used as RobotId for loading historical messages during voice calls.
Receiving user messages from ZIM, preprocessing messages including sensitive word filtering and preliminary intent recognition.
Calling LLM service to send processed user messages to LLM for deep analysis and content generation.
After receiving LLM response content, post-processing the reply including format output and secondary content safety verification.
Calling ZIM backend API to send replies back to clients as the bot through ZIM.
Voice Call
Client APP: Integrates ZEGO Express SDK to implement voice call functionality.
Business Backend: Calls the create agent instance API and passes the bot's UserId as the RobotId parameter to AI Agent service.
AI Agent Backend: Based on the RobotId passed from business backend, loads historical messages from ZIM backend as input context for the agent. The LLM configured for the agent will use this context as chat history to interact with users in voice calls and answer user questions.
Sample Code
The following are client sample codes for integrating ZIM SDK to implement In-app Chat and business backend sample codes for integrating ZIM and real-time interactive AI Agent APIs. You can refer to these samples to implement your own business logic.

Note
Please use the im_and_voice branch code for the following examples.
Android Client Sample Code
Includes basic capabilities such as login, sending/receiving text messages, publishing stream, playing stream, and leaving room.

iOS Client Sample Code
Includes basic capabilities such as login, sending/receiving text messages, publishing stream, playing stream, and leaving room.

Web Client Sample Code
Includes basic capabilities such as login, sending/receiving text messages, publishing stream, playing stream, and leaving room.

Flutter Client Sample Code
Includes basic capabilities such as login, sending/receiving text messages, publishing stream, playing stream, and leaving room.

Business Backend Sample Code
Includes basic capabilities such as obtaining ZEGOCLOUD Token, registering ZIM bots, registering agents, creating agent instances, and deleting agent instances.

Here's the implementation result:


Quick Implementation of In-app Chat with AI
1. Set Up Business Backend
The business backend serves as a bridge connecting ZIM and LLM. You can use any backend technology stack you're familiar with, such as Node.js, Python, Java, Go, etc.

1.1 Register ZIM Bot
In-app Chat and AI Agent service need to receive and send messages through ZIM bots. Therefore, you need to specify a bot UserId (i.e., RobotId) and call ZIM backend API to register a bot.

For detailed registration instructions, please refer to ZIM Bot Registration Instructions.

Note
Usually, you only need to register once when creating a new bot. Subsequent chats and calls don't require re-registration.
1.2 Set Up ZIM Callbacks to Receive User Messages
Configure ZIM backend to notify your business backend of message events through callback mechanisms. For detailed configuration instructions, please refer to ZIM Callback Configuration Instructions.

Your business backend needs to implement an HTTP interface to listen for Message Sent Callbacks. Here's sample callback data:

ZIM Message Callback Sample (Peer Text Message)
{
    "appid": "1",
    "event": "send_msg",
    "nonce": "350176",
    "signature": "signature",
    "timestamp": 1679553625,
    "from_user_id": "user_id_1",
    "conv_type": 0,
    "conv_id": "@RBT#AIAgentExample1",
    "msg_type": 1,
    "msg_body": "msg_body",
    "msg_id": "857639062792568832",
    "payload": "payload",
    "msg_time": 1679554146000,
    "send_result": 0,
    "sub_msg_type": 0,
    "user_list":[
    ]
}
ZIM Message Callback Sample (Peer Text Message)

{
    "appid": "1",
    "event": "send_msg",
    "nonce": "350176",
    "signature": "signature",
    "timestamp": 1679553625,
    "from_user_id": "user_id_1",
    "conv_type": 0,
    "conv_id": "@RBT#AIAgentExample1",
    "msg_type": 1,
    "msg_body": "msg_body",
    "msg_id": "857639062792568832",
    "payload": "payload",
    "msg_time": 1679554146000,
    "send_result": 0,
    "sub_msg_type": 0,
    "user_list":[
    ]
}
1.3 Call LLM Service to Generate AI Replies
After receiving user messages from callbacks, the business backend needs to call LLM service to generate AI replies. You can use LLM services provided by third-party service providers such as DeepSeek, Volcano Ark (DouBao), MiniMax, Volcano Engine, Alibaba Cloud, StepFun, OpenAI (GPT series), or self-deployed LLM services.

Please refer to the relevant service provider's API documentation for integration. Here's sample code for calling DeepSeek model using Node.js:

Node.js DeepSeek Example
async function generateLLMResponse(messages: MessageItem[]): Promise<string> {
    try {
        console.log('Preparing to generate LLM response, message context:', messages);
        // Get LLM configuration from environment variables
        const apiKey = process.env.LLM_API_KEY;
        const baseURL = process.env.LLM_BASE_URL;
        const model = process.env.LLM_MODEL || 'deepseek-v3-250324';
        if (!apiKey || !baseURL) {
            console.error('Missing LLM configuration, please check environment variables');
            return "Sorry, I'm temporarily unable to reply to your message. Please try again later.";
        }

        // Convert message format
        const formattedMessages = messages.map(msg => ({
            role: msg.role as "user" | "assistant" | "system",
            content: msg.content
        }));

        // Add system prompt
        formattedMessages.unshift({
            role: "system",
            content: "You are a helpful assistant. Please answer user questions concisely and clearly."
        });

        // Use fetch API to call LLM service. Note: using non-streaming response.
// !mark(1:11)
        const response = await fetch(baseURL, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                messages: formattedMessages,
                model: model
            })
        });

        if (!response.ok) {
            throw new Error(`LLM API request failed: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();

        // Get reply content
        const reply = data.choices?.[0]?.message?.content || "Sorry, I cannot generate a reply.";
        return reply;
    } catch (error) {
        console.error('Error generating LLM response:', error);
        return "Sorry, there was an issue processing your request. Please try again later.";
    }
}
Node.js DeepSeek Example

async function generateLLMResponse(messages: MessageItem[]): Promise<string> {
    try {
        console.log('Preparing to generate LLM response, message context:', messages);
        // Get LLM configuration from environment variables
        const apiKey = process.env.LLM_API_KEY;
        const baseURL = process.env.LLM_BASE_URL;
        const model = process.env.LLM_MODEL || 'deepseek-v3-250324';
        if (!apiKey || !baseURL) {
            console.error('Missing LLM configuration, please check environment variables');
            return "Sorry, I'm temporarily unable to reply to your message. Please try again later.";
        }

        // Convert message format
        const formattedMessages = messages.map(msg => ({
            role: msg.role as "user" | "assistant" | "system",
            content: msg.content
        }));

        // Add system prompt
        formattedMessages.unshift({
            role: "system",
            content: "You are a helpful assistant. Please answer user questions concisely and clearly."
        });

        // Use fetch API to call LLM service. Note: using non-streaming response.
        const response = await fetch(baseURL, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                messages: formattedMessages,
                model: model
            })
        });

        if (!response.ok) {
            throw new Error(`LLM API request failed: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();

        // Get reply content
        const reply = data.choices?.[0]?.message?.content || "Sorry, I cannot generate a reply.";
        return reply;
    } catch (error) {
        console.error('Error generating LLM response:', error);
        return "Sorry, there was an issue processing your request. Please try again later.";
    }
}
1.4 Send AI Reply Back to Client via ZIM
After obtaining the LLM reply, the business backend needs to use ZIM backend API to send this reply content to the real user as AI.

For specific API usage, please refer to the Send Peer Message interface in ZIM backend API documentation.

Here's an example of sending messages through ZIM backend API using Node.js:

Node.js
async function sendReplyMessage(fromUserId: string, toUserId: string, message: string) {
    try {
        // Build message body
        const messageBody = {
            Message: message, // LLM reply content
            ExtendedData: ''
        };

        // Send message
        // ZegoZIM.getInstance().sendPeerMessage is a demo wrapper method. For complete implementation, refer to: https://github.com/ZEGOCLOUD/ai_agent_quick_start_server/blob/im_and_voice/src/lib/zego/zim.ts#L162
        // Please refer to detailed send peer message API documentation: https://www.zegocloud.com/docs/zim-server/messaging/send-a-one-to-one-message
        const result = await ZegoZIM.getInstance().sendPeerMessage(
// !mark(1:2)
            fromUserId,                  // Sender ID, i.e., UserInfo.UserId from bot registration (Bot ID)
            [toUserId],                  // Receiver ID array (Real user ID)
            ZegoMessageType.Text,        // Message type: Text
            messageBody,                 // Message content
            ZegoMessagePriority.Medium   // Message priority: Medium
        );

        console.log('Send reply message result:', result);
        return result;
    } catch (error) {
        console.error('Error sending reply message:', error);
        throw error;
    }
}
Node.js

async function sendReplyMessage(fromUserId: string, toUserId: string, message: string) {
    try {
        // Build message body
        const messageBody = {
            Message: message, // LLM reply content
            ExtendedData: ''
        };

        // Send message
        // ZegoZIM.getInstance().sendPeerMessage is a demo wrapper method. For complete implementation, refer to: https://github.com/ZEGOCLOUD/ai_agent_quick_start_server/blob/im_and_voice/src/lib/zego/zim.ts#L162
        // Please refer to detailed send peer message API documentation: https://www.zegocloud.com/docs/zim-server/messaging/send-a-one-to-one-message
        const result = await ZegoZIM.getInstance().sendPeerMessage(
            fromUserId,                  // Sender ID, i.e., UserInfo.UserId from bot registration (Bot ID)
            [toUserId],                  // Receiver ID array (Real user ID)
            ZegoMessageType.Text,        // Message type: Text
            messageBody,                 // Message content
            ZegoMessagePriority.Medium   // Message priority: Medium
        );

        console.log('Send reply message result:', result);
        return result;
    } catch (error) {
        console.error('Error sending reply message:', error);
        throw error;
    }
}
2. Client Processing Logic
The client's ZIM SDK will listen for and receive AI reply messages from the business backend (forwarded through ZIM backend). You need to implement message receiving logic on the client side and display the content in the user interface.

Prerequisites
Please integrate ZIM SDK in your client APP. Refer to integration guides for each platform:

ZIM Android SDK Integration
ZIM iOS SDK Integration
ZIM Web SDK Integration
2.1 Get Historical Messages from AI Conversations
When entering the AI chat page, you need to retrieve historical messages from ZIM service. Here are sample codes for implementing historical message retrieval on each platform:


Android

Web

iOS

flutter
Android
ZIMMessageQueryConfig queryConfig = new ZIMMessageQueryConfig();
queryConfig.count = 100;     // Query count
queryConfig.reverse = true;  // Query the latest count messages

// !mark(1:2)
String conversationId ; // Conversation ID for querying historical messages. i.e., bot `UserId` (i.e., RobotId)
ZIM.getInstance().queryHistoryMessage(conversationId, ZIMConversationType.PEER, queryConfig,new ZIMMessageQueriedCallback() {
    @Override
    public void onMessageQueried(String conversationID, ZIMConversationType conversationType,ArrayList<ZIMMessage> messageList, ZIMError errorInfo) {
        if (errorInfo.code == ZIMErrorCode.SUCCESS) {
            //  Success
        } else {
           // Failure
        }
    }
});

ZIMMessageQueryConfig queryConfig = new ZIMMessageQueryConfig();
queryConfig.count = 100;     // Query count
queryConfig.reverse = true;  // Query the latest count messages

String conversationId ; // Conversation ID for querying historical messages. i.e., bot `UserId` (i.e., RobotId)
ZIM.getInstance().queryHistoryMessage(conversationId, ZIMConversationType.PEER, queryConfig,new ZIMMessageQueriedCallback() {
    @Override
    public void onMessageQueried(String conversationID, ZIMConversationType conversationType,ArrayList<ZIMMessage> messageList, ZIMError errorInfo) {
        if (errorInfo.code == ZIMErrorCode.SUCCESS) {
            //  Success
        } else {
           // Failure
        }
    }
});
2.2 Send Messages to AI
After users input messages on the client, you can use ZIM SDK to send messages to AI. Here are sample codes for implementing message sending on each platform:


Android

Web

iOS

flutter
Android
String text ; // Chat text
// !mark
String conversationId ; // Conversation ID for sending messages. i.e., bot `UserId` (i.e., RobotId)
ZIMTextMessage zimMessage = new ZIMTextMessage();
zimMessage.message = text;
// In peer chat scenario, set ZIMConversationType to PEER
// !mark
ZIM.getInstance().sendMessage(zimMessage, conversationId, ZIMConversationType.PEER, new ZIMMessageSendConfig(),
    new ZIMMessageSentFullCallback() {
        @Override
        public void onMessageAttached(ZIMMessage message) {
            // Insert message to list when sending starts
        }

        @Override
        public void onMessageSent(ZIMMessage message, ZIMError errorInfo) {
            // Send success
        }

        @Override
        public void onMediaUploadingProgress(ZIMMediaMessage message, long currentFileSize,
            long totalFileSize) {

        }

        @Override
        public void onMultipleMediaUploadingProgress(ZIMMultipleMessage message, long currentFileSize,
            long totalFileSize, int messageInfoIndex, long currentIndexFileSize, long totalIndexFileSize) {

        }
    });

String text ; // Chat text
String conversationId ; // Conversation ID for sending messages. i.e., bot `UserId` (i.e., RobotId)
ZIMTextMessage zimMessage = new ZIMTextMessage();
zimMessage.message = text;
// In peer chat scenario, set ZIMConversationType to PEER
ZIM.getInstance().sendMessage(zimMessage, conversationId, ZIMConversationType.PEER, new ZIMMessageSendConfig(),
    new ZIMMessageSentFullCallback() {
        @Override
        public void onMessageAttached(ZIMMessage message) {
            // Insert message to list when sending starts
        }

        @Override
        public void onMessageSent(ZIMMessage message, ZIMError errorInfo) {
            // Send success
        }

        @Override
        public void onMediaUploadingProgress(ZIMMediaMessage message, long currentFileSize,
            long totalFileSize) {

        }

        @Override
        public void onMultipleMediaUploadingProgress(ZIMMultipleMessage message, long currentFileSize,
            long totalFileSize, int messageInfoIndex, long currentIndexFileSize, long totalIndexFileSize) {

        }
    });
2.3 Receive AI Reply Messages
AI reply messages will be sent to the client through ZIM service via the business backend. You need to implement message receiving logic on the client side and display the content in the user interface. Here are sample codes for implementing message receiving on each platform:


Android

Web

iOS

flutter
Android
ZIM.getInstance().setEventHandler(new ZIMEventHandler() {
    @Override
// !mark
    public void onPeerMessageReceived(ZIM zim, ArrayList<ZIMMessage> messageList, ZIMMessageReceivedInfo info,String fromUserID) {
        // Only add messages from this conversation to this page
        List<ZIMMessage> collect = messageList.stream()
            .filter(zimMessage -> Objects.equals(Constant.agent_zim_robotid, zimMessage.getConversationID()))
            .collect(Collectors.toList());
    }
});

ZIM.getInstance().setEventHandler(new ZIMEventHandler() {
    @Override
    public void onPeerMessageReceived(ZIM zim, ArrayList<ZIMMessage> messageList, ZIMMessageReceivedInfo info,String fromUserID) {
        // Only add messages from this conversation to this page
        List<ZIMMessage> collect = messageList.stream()
            .filter(zimMessage -> Objects.equals(Constant.agent_zim_robotid, zimMessage.getConversationID()))
            .collect(Collectors.toList());
    }
});
Asynchronous Processing and User Feedback
To avoid UI freezing or unresponsiveness due to lengthy LLM processing time, you can use the following methods to optimize interaction:

After the client sends a message, you can immediately display "AI is thinking..." or similar waiting prompts in the interface.
After the business backend receives user messages, it can quickly respond to the client that the message has been received, then asynchronously call LLM service. When LLM returns results, push the actual reply to the client through ZIM to update the interface.
Quick Implementation of Voice Calls with AI
In real application scenarios, users may switch between text and voice interactions. To maintain conversation continuity and context integrity, please refer to the following instructions to implement the association between In-app Chat historical messages and voice call messages.

Associate In-app Chat Historical Messages to Voice Calls
Note
Please first refer to the Quick Start document to implement voice call functionality with AI.
Before starting a call, you can associate In-app Chat historical messages to voice calls in the following way:

When creating an agent instance, configure the MessageHistory parameter:

Set MessageHistory.SyncMode (message sync mode) to 0, indicating synchronization from ZIM historical messages
Provide complete ZIM-related information in MessageHistory.ZIM, including:
RobotId: The UserInfo.UserId corresponding to the ZIM bot registration API call
LoadMessageCount: When creating agent instance, how many messages to fetch from ZIM service as context. Defaults to WindowSize value (upper limit).
After completing the above configuration, the created agent instance will automatically retrieve In-app Chat historical messages as LLM historical message input during voice interactions.

Associate Voice Call Context to In-app Chat
After the call ends, all voice call messages will be synchronized to ZIM service. You can synchronize these messages to In-app Chat after the call ends to maintain conversation continuity and context integrity.

For detailed steps, refer to the Get Historical Messages from AI Conversations section.
API Reference
Overview
API Overview
ZEGOCLOUD AI Agent server provides the following relevant API interfaces and callbacks. You can refer to Accessing Server APIs to call the interfaces below.

Agent Configuration Management
Interface Name	Interface Function	Default Call Frequency Limit
Register An Agent	Register an agent (Agent) for creating an agent instance.	10 times/second
Unregister An Agent	Unregister an agent.	10 times/second
Update An Agent	Modify an agent.	10 times/second
List Agents	Get the list of available agents.	10 times/second
Query Agent Details	Get the details of a specified agent.	10 times/second
Agent Instance Management
Interface Name	Interface Function	Default QPS limit
Create An Agent Instance	Create an agent instance and add it to text conversations and voice (RTC) conversations.	10 times/second
Update An Agent Instance	Update an existing agent instance.	10 times/second
Delete An Agent Instance	Delete an existing agent instance.	10 times/second
Agent Instance Control
Interface Name	Interface Function	Default QPS limit
Trigger LLM	Trigger the LLM service as a user, and based on the response content from the LLM, proactively invoke the TTS service as an agent to send voice messages to the user.	10 times/second
Trigger TTS	Trigger the TTS service as an agent to send voice messages to the user.	10 times/second
Query The Status of An AI Agent Instance	Query the runtime status information of the agent during voice conversations.	10 times/second
Interrupt Agent Instance	Interrupt the agent instance in a voice conversation	10 times/second
Get Agent Instance Context	get the message list as context used by the agent instance during a voice conversation.	10 times/second
Reset Agent Instance Context	Reset the message list as context used by the agent instance during a voice conversation.	10 times/second
Callbacks
Callback Name	Callback Description
Receiving Callback	With this callback, listen to events that occur during the user's conversation with the agent.
API Reference
Call API Online
How to Call Server API Online
You can call the server API online in the ZEGOCLOUD server API documentation page to quickly test and verify the functionality of the API. Please use the signature generator to generate the necessary request parameters for the API, and then go to the corresponding interface page for debugging.

Use Online Signature Generator to Generate API Required Request Parameters
Please get the AppId and ServerSecret from the ZEGOCLOUD Console, then fill in the following input box and click the Generate button to generate the signature.

Note
The operation of calculating the signature is completed on the client side, and no data is sent to the server.
Attention
Please make sure the AppId and ServerSecret are correct.
The generated signature is used for authentication when calling the server API.
The signature is time-sensitive, so please use it promptly. If the interface returns an error indicating that the signature has expired, please generate a new one.
Signature Generator
ServerSecret:
Enter ServerSecret
Copy
AppId:
Enter AppId
Copy
SignatureNonce:
Filled after clicking the Generate button
Copy
Timestamp:
Filled after clicking the Generate button
Copy
Signature:
Filled after clicking the Generate button
Copy
Generate Signature
Online Debugging Operation Demonstration
Attention
If the Send button is clicked and the page does not respond, please try refreshing the page or generating new public parameters.
The page should be refreshed when switching to a different interface for debugging.
API Reference
Return Codes
Return Codes
Common Return Codes
Return Code	Description	Suggested Action
0	Success	-
100000000	Incorrect Host in the request header.	Please confirm whether the Host address in the request header is correct.
100000001	Incorrect format of AppId field.	Please fill in the correct AppId.
100000002	Timestamp field is empty.	Please fill in the Timestamp.
100000003	Incorrect format of Timestamp field.	Please fill in the correct Unix timestamp (in seconds).
100000004	Signature expired.	Please regenerate the signature.
100000005	Signature error.	Please confirm whether the parameters used to generate the signature are correct.
100000006	Action is empty.	Please specify the Action.
100000007	Unsupported Action.	Please fill in the correct Action.
100000008	SignatureNonce field is empty.	Please fill in the SignatureNonce.
100000009	Signature field is empty.	Please fill in the Signature.
100000010	Failed to get ServerSecret.	Please confirm whether the AppId is correct.
100000011	Failed to get App configuration.	Please confirm whether the AppId is correct, or contact ZEGOCLOUD technical support for assistance.
100000012	Failed to read HTTP packet body.	Please contact ZEGOCLOUD technical support for assistance.
100000013	SignatureVersion field is empty.	Please fill in the SignatureVersion.
100000014	Unsupported SignatureVersion.	SignatureVersion only supports 2.0.
100000015	Internal gateway error.	Please contact ZEGOCLOUD technical support for assistance.
100000017	The App has not enabled this service.	Please contact ZEGOCLOUD technical support for assistance.
Business Return Codes
Return Code	Description	Suggested Action
410000001	System error.	Please contact ZEGOCLOUD technical support for handling.
410000002	Invalid AppID.	Please check if the AppID is correct.
410000003	Invalid parameter.	Please check the illegal input parameters according to the Message prompt.
410000004	JSON parsing failed.	Please check if the request parameters are valid JSON.
410000005	Gateway authentication failed.	Please contact ZEGOCLOUD technical support for handling.
410000006	The App has not enabled this service.	Please contact ZEGOCLOUD technical support for handling.
410000009	Internal service call failed.	Please contact ZEGOCLOUD technical support for handling.
410000010	Insufficient service resources.	Please contact ZEGOCLOUD technical support for handling.
410000011	APP online instance concurrency limit.	Please check if the concurrency limit has been reached, and contact ZEGOCLOUD technical support for handling.
410001002	AI agent instance not found.	Please check if the AI agent instance has been deleted.
410001003	AI agent instance creation failed.	Please contact ZEGOCLOUD technical support for handling.
410001004	AI agent instance modification failed.	Please contact ZEGOCLOUD technical support for handling.
410001005	AI agent instance deletion failed.	Please contact ZEGOCLOUD technical support for handling.
410001006	Active LLM call failed.	Please contact ZEGOCLOUD technical support for handling.
410001007	Active TTS call failed.	Please contact ZEGOCLOUD technical support for handling.
410001008	AI agent already exists.	Do not create duplicates.
410001009	AI agent not found.	Please check if the AI agent has been created.
410001010	Failed to load the message history.	Please contact ZEGOCLOUD technical support for handling.
410001011	AI agent instance update failed.	Please contact ZEGOCLOUD technical support for handling.
410001013	AI agent is listening.	When the AI agent is listening, you can not active trigger LLM or TTS.
410001022	Failed to get the agent instance context.	Please contact ZEGOCLOUD technical support for handling.
410001023	Failed to reset the agent instance context.	Please contact ZEGOCLOUD technical support for handling.
410001024	Failed to interrupt the agent instance.	Please contact ZEGOCLOUD technical support for handling.
API Reference
Agent Configuration Management
Register Agent
RegisterAgent
POST
https://aigc-aiagent-api.zegotech.cn/
By calling this API, you can register an AI agent (Agent) for creating AI agent instances.

Request
Query Parameters
Action
string
required
Possible values: [RegisterAgent]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=RegisterAgent

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentId
string
required
Possible values: <= 128 characters

Only supports numbers, English characters, and the following special characters: !#$%&()+-:;<=.>?@[]^_{}|~,.

Name
string
Possible values: <= 256 characters

AI Agent name, with a maximum length of 256 bytes.

LLM
object
required
TTS
object
required
ASR
object
Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID
API Reference
Agent Configuration Management
Unregister Agent
UnregisterAgent
POST
https://aigc-aiagent-api.zegotech.cn/
By calling this API, you can unregister an AI agent.

Request
Query Parameters
Action
string
required
Possible values: [UnregisterAgent]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=UnregisterAgent

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentId
string
required
The unique identifier of the registered AI agent.

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID
API Reference
Agent Configuration Management
Update Agent
UpdateAgent
POST
https://aigc-aiagent-api.zegotech.cn/
By calling this API, you can update an existing AI agent.

ðŸ“Œ Note: Only parameters passed in this interface will take effect; parameters not passed will not be updated.

Request
Query Parameters
Action
string
required
Possible values: [UpdateAgent]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=UpdateAgent

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentId
string
required
The unique identifier of the registered AI agent.

Name
string
Possible values: <= 64 characters

AI Agent name

LLM
object
TTS
object
ASR
object
Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID
API Reference
Agent Configuration Management
List Agents
ListAgents
POST
https://aigc-aiagent-api.zegotech.cn/
By calling this API, you can obtain a list of available AI agents.

Request
Query Parameters
Action
string
required
Possible values: [ListAgents]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=ListAgents

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
Limit
integer
Possible values: >= 0 and <= 10

Default value: 5

The number of AI agent information entries to retrieve in one request. The value range is [0, 10]. If not filled or the value is 0, it defaults to 5. If the value is less than 0 or greater than 10, the API request will return an error.

Cursor
string
Pagination retrieval marker. Leave blank for the first request, then fill in the Cursor value returned from the previous response. When the returned Cursor is empty, it indicates that the list of AI agents has been fully retrieved.

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Example
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID

Data
object
Total
integer
Total number of AI agents that meet the query criteria

Agents
object[]
AI Agent list
Array
[
AgentId
string
AI agent unique identifier

Name
string
AI agent name

LLM
object
Url
string
required
The endpoint that receives the request (can be your own service or any LLM service provider's service) and must be compatible with OpenAI Chat Completions API.

For example: https://api.openai.com/v1/chat/completions

ðŸ“Œ Important Note

If ApiKey is set to "zego_test", you must use one of the following Url addresses:

MiniMaxï¼šhttps://api.minimax.chat/v1/text/chatcompletion_v2
Volcano Engine (Doubao): https://ark.cn-beijing.volces.com/api/v3/chat/completions
Aliyun Bailei (Tongyi Qianwen): https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
Stepfun: https://api.stepfun.com/v1/chat/completions
ApiKey
string
The parameter used for authentication by the LLM service provider. It is empty by default, but must be provided in production environments.

ðŸ“Œ Important Note

During the test period (within 2 weeks after the AI Agent service is enabled), you can set this parameter value to "zego_test" to use this service.

Model
string
required
The LLM model. Different LLM service providers support different models, please refer to their official documentation to select the appropriate model.

ðŸ“Œ Important Note

If ApiKey is set to "zego_test", you must use one of the following models:

MiniMax:
MiniMax-Text-01
Volcano Engine (Doubao):
doubao-1-5-pro-32k-250115
doubao-1-5-lite-32k-250115
Aliyun Bailei (Tongyi Qianwen):
qwen-plus
Stepfun:
step-2-16k
SystemPrompt
string
The system prompt of the AI agent. It is the predefined information that is added at the beginning when calling the LLM, used to control the output of the LLM. It can be role settings, prompts, and answer examples.

Temperature
number
Possible values: >= 0 and <= 2

Default value: 0.7

The higher the value, the more random the output; the lower the value, the more concentrated and determined the output.

TopP
number
Possible values: >= 0 and <= 1

Default value: 0.9

The sampling method. The smaller the value, the stronger the determinism; the larger the value, the stronger the randomness.

Params
object
Other parameters supported by the LLM service provider, such as the maximum token limit. Different LLM providers support different parameters, please refer to their official documentation and fill in as needed.

AddAgentInfo
boolean
Default value: false

If this value is true, the AI Agent server will include the AI agent information in the request parameters when requesting the LLM service. You can use this parameter to execute additional business logic in your custom LLM service.

The structure of agent_info is as follows:

room_id: RTC room ID
user_id: User ID
agent_instance_id: AI agent instance ID
TTS
object
Vendor
string
required
Possible values: [Aliyun, ByteDance, ByteDanceFlowing, MiniMax, CosyVoice]

The TTS service provider. Options:

Aliyun: Aliyun
ByteDance: ByteDance (Volcano Voice - Large Model Speech Synthesis API)
ByteDanceFlowing: ByteDance (Volcano Voice - Streaming Speech Synthesis API (WebSocket))
MiniMax: MiniMax
CosyVoice: Aliyun CosyVoice
Params
object
required
TTS configuration parameters, in JSON object format. Contains app parameters (for authentication) and other parameters (for adjusting TTS effects).


In addition to the app parameter, you can also pass in other TTS configuration parameters to adjust the speech synthesis effect. These parameters will be directly passed to the corresponding TTS service provider.

You can refer to the official documentation of the service provider for the required information according to the value of Vendor.

- Aliyun: Intelligent Speech Interaction - Overview of speech synthesis - 2. Start the synthesis task

- ByteDance: Large Model Speech Synthesis API - Parameter List - Request Parameters

- ByteDanceFlowing: "Payload request parameters" in Streaming Text-to-Speech API (WebSocket) - WebSocket Binary Protocol

- MiniMax: Voice Model - T2A v2 - WebSocket API - Interface Parameters

- CosyVoice: "Payload request parameters" in CosyVoice WebSocket API for Speech Synthesis

app
object
required
other_params
string
ðŸ“Œ Important Note

other_params is not a valid parameter, it is only used to demonstrate how to pass vendor parameters. Except for the app parameter, other parameters are directly passed to the vendor parameters.

The following are the parameter filling examples for each vendor, please fill in according to your actual needs:

Aliyun:
"TTS": {
    "Vendor": "Aliyun",
    "Params": {
        "app":{
            "app_key": "your key",
            "ak_id": "your ak id",
            "ak_key": "your ak key"
        },
        "voice": "zhitian_emo"
    }
}

"TTS": {
    "Vendor": "Aliyun",
    "Params": {
        "app":{
            "app_key": "your key",
            "ak_id": "your ak id",
            "ak_key": "your ak key"
        },
        "voice": "zhitian_emo"
    }
}
ByteDance:
/*
    cluster configuration description: 
    default: volcano_tts: normal voice cluster
          volcano_mega: voice clone large model 1.0
          volcano_icl: voice clone large model 2.0
*/

"TTS": {
    "Vendor": "ByteDance",
    "Params": {
        "app": {
            "appid": "your_appid",
            "token": "your_token",
            "cluster": "volcano_tts"
        },
        "audio": {
            "voice_type": "your_voice_type"
        }
    }
}

/*
    cluster configuration description: 
    default: volcano_tts: normal voice cluster
          volcano_mega: voice clone large model 1.0
          volcano_icl: voice clone large model 2.0
*/

"TTS": {
    "Vendor": "ByteDance",
    "Params": {
        "app": {
            "appid": "your_appid",
            "token": "your_token",
            "cluster": "volcano_tts"
        },
        "audio": {
            "voice_type": "your_voice_type"
        }
    }
}
ByteDanceFlowing:
/*
    resource_id configuration description: 
    default: volc.service_type.10029, that is: Volcano large model speech synthesis
    voice clone 2.0:
       volc.megatts.defaultï¼ˆhour versionï¼‰
       volc.megatts.concurrï¼ˆconcurrent versionï¼‰ 
    âš ï¸ï¼ˆvoice clone 1.0 is not supportedï¼‰
    âš ï¸Note: speaker (voice id) and resource_id must match
*/

"TTS": {
    "Vendor": "ByteDanceFlowing",
    "Params": {
        "app": {
            "appid": "your appid",
            "token": "your token",
            "resource_id": "volc.service_type.10029" // voice resourceid
        },
        "req_params": {
            "speaker": "zh_female_qingxinnvsheng_mars_bigtts" //voice id
        }
    }
}

/*
    resource_id configuration description: 
    default: volc.service_type.10029, that is: Volcano large model speech synthesis
    voice clone 2.0:
       volc.megatts.defaultï¼ˆhour versionï¼‰
       volc.megatts.concurrï¼ˆconcurrent versionï¼‰ 
    âš ï¸ï¼ˆvoice clone 1.0 is not supportedï¼‰
    âš ï¸Note: speaker (voice id) and resource_id must match
*/

"TTS": {
    "Vendor": "ByteDanceFlowing",
    "Params": {
        "app": {
            "appid": "your appid",
            "token": "your token",
            "resource_id": "volc.service_type.10029" // voice resourceid
        },
        "req_params": {
            "speaker": "zh_female_qingxinnvsheng_mars_bigtts" //voice id
        }
    }
}
Minimax:
"TTS": {
    "Vendor": "MiniMax",
    "Params": {
        "app": {
            "group_id": "your_group_id",
            "api_key":  "your_api_key",
        },
        "model": "speech-02-turbo-preview",
        "voice_setting": {
            "voice_id": "male-qn-qingse"
        }
    }
}

"TTS": {
    "Vendor": "MiniMax",
    "Params": {
        "app": {
            "group_id": "your_group_id",
            "api_key":  "your_api_key",
        },
        "model": "speech-02-turbo-preview",
        "voice_setting": {
            "voice_id": "male-qn-qingse"
        }
    }
}
CosyVoice:
{
    "Vendor": "CosyVoice",
    "Params": {
        "app": {
            "api_key": "your_api_key"
        },
        "payload": {
            "model": "cosyvoice-v2",
            "parameters": {
                "voice": "longxiaochun_v2"
            }
        }
    }
}

{
    "Vendor": "CosyVoice",
    "Params": {
        "app": {
            "api_key": "your_api_key"
        },
        "payload": {
            "model": "cosyvoice-v2",
            "parameters": {
                "voice": "longxiaochun_v2"
            }
        }
    }
}
FilterText
object[]
Filter the text within the specified punctuation marks from the content returned by the LLM, and then perform speech synthesis.Note:- The content that should be placed within the specified punctuation marks must be defined in LLM > SystemPrompt.- This parameter cannot be updated when updating the AI agent instance.
Array
[
BeginCharacters
string
required
The start punctuation mark of the filtered text. For example, if you want to filter the content in (), set it to (.

EndCharacters
string
required
The end punctuation mark of the filtered text. For example, if you want to filter the content in (), set it to ).

]
TerminatorText
string
Possible values: <= 4 characters

Can be used to set the termination text of TTS. If the content in the input TTS text matches the TerminatorText string, the content from the TerminatorText string (including) will not be synthesized for this round of TTS.

ðŸ“Œ Important Note

Only one character can be set for bidirectional streaming.

ASR
object
HotWord
string
The hot word list is used to improve the recognition accuracy. Format: Hotword1|Weight1,Hotword2|Weight2,Hotword3|Weight3

A single hot word cannot exceed 30 characters, cannot contain spaces, and the weight range is [-1, 11]. Up to 128 hot words are supported.

ðŸ“Œ Important Note

When the weight is 11, it means that the word is a super hot word. It is recommended to set only the important and must-take-effect hot words to 11, and too many hot words with a weight of 11 will affect the recognition effect.

Params
object
Extended parameters, please contact ZEGOCLOUD technical support for details.

VADSilenceSegmentation
number
Possible values: >= 200 and <= 2000

Default value: 500

Set the time after which the user's speech is no longer considered as a sentence. The unit is ms, range [200, 2000], default is 500.

PauseInterval
number
Possible values: >= 200 and <= 2000

Set the time within which two sentences are considered as one sentence, i.e., ASR multi-sentence concatenation. The unit is ms, range [200, 2000]. Only when this value is greater than VADSilenceSegmentation, ASR multi-sentence concatenation will be enabled.

]
Cursor
string
A non-empty value only indicates that there are still AI agent details not returned, and you need to set this field in the request parameter Cursor to fetch more AI agent information; an empty value indicates that all AI agent information has been returned.
API Reference
Agent Configuration Management
Query Agents Details
QueryAgents
POST
https://aigc-aiagent-api.zegotech.cn/
By calling this API, you can query AI agent information.

Request
Query Parameters
Action
string
required
Possible values: [QueryAgents]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=QueryAgents

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentIds
string[]
required
Possible values: <= 10

A list of registered AI agent IDs, with a maximum length of 10.

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Example
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID

Data
object
API Reference
Agent Instance Management
Create Agent Instance
CreateAgentInstance
POST
https://aigc-aiagent-api.zegotech.cn/
By calling this interface, you can create an AI agent instance and add it to a voice (RTC) conversation.

Note
If there is no real user in the RTC room after 120 seconds, the AI agent instance will automatically be destroyed, and the Event will be AgentInstanceDeleted callback, and the Data.Code will be 1202.

Request
Query Parameters
Action
string
required
Possible values: [CreateAgentInstance]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=CreateAgentInstance

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentId
string
required
The unique identifier of the registered AI agent.

UserId
string
required
Possible values: <= 32 characters

The real user ID used to log in to the RTC room. Only numbers, English characters, '-', and '_' are supported.

RTC
object
required
LLM
object
TTS
object
ASR
object
MessageHistory
object
CallbackConfig
object
AdvancedConfig
object
Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID

Data
object
API Reference
Agent Instance Management
Create Agent Instance
CreateAgentInstance
POST
https://aigc-aiagent-api.zegotech.cn/
By calling this interface, you can create an AI agent instance and add it to a voice (RTC) conversation.

Note
If there is no real user in the RTC room after 120 seconds, the AI agent instance will automatically be destroyed, and the Event will be AgentInstanceDeleted callback, and the Data.Code will be 1202.

Request
Query Parameters
Action
string
required
Possible values: [CreateAgentInstance]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=CreateAgentInstance

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentId
string
required
The unique identifier of the registered AI agent.

UserId
string
required
Possible values: <= 32 characters

The real user ID used to log in to the RTC room. Only numbers, English characters, '-', and '_' are supported.

RTC
object
required
LLM
object
TTS
object
ASR
object
MessageHistory
object
CallbackConfig
object
AdvancedConfig
object
Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID

Data
object

API Reference
Agent Instance Management
Create Digital Human Agent Instance
CreateDigitalHumanAgentInstance
POST
https://aigc-aiagent-api.zegotech.cn/
With this interface, you can create a digital human agent instance and join the agent instance into a voice (RTC) conversation.

Note
If the RTC room is not occupied by a real user after 120 seconds, the agent instance will be automatically destroyed, and the Event will be AgentInstanceDeleted callback, and the Data.Code will be 1202.

Request
Query Parameters
Action
string
required
Possible values: [CreateDigitalHumanAgentInstance]

Interface prototype parameters

https://aigc-aiagent-api.zegotech.cn?Action=CreateDigitalHumanAgentInstance

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentId
string
required
The unique identifier of the registered AI agent.

UserId
string
required
Possible values: <= 32 characters

The real user ID used to log in to the RTC room. Only numbers, English characters, '-', and '_' are supported.

RTC
object
required
LLM
object
TTS
object
ASR
object
MessageHistory
object
CallbackConfig
object
AdvancedConfig
object
DigitalHuman
object
required
Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID

Data
object
API Reference
Agent Instance Management
Update Agent Instance
UpdateAgentInstance
POST
https://aigc-aiagent-api.zegotech.cn/
With this interface, you can update the configuration of the AI agent instance.

ðŸ“Œ Note: Only parameters passed into this interface will take effect, and parameters not passed in will not be updated.

Request
Query Parameters
Action
string
required
Possible values: [UpdateAgentInstance]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=UpdateAgentInstance

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentInstanceId
string
required
The unique identifier of the AI agent instance, obtained through the response parameters of the Create AI Agent Instance interface.

LLM
object
TTS
object
ASR
object
Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID

API Reference
Agent Instance Management
Delete Agent Instance
DeleteAgentInstance
POST
https://aigc-aiagent-api.zegotech.cn/
With this interface, you can delete an existing AI agent instance.

Request
Query Parameters
Action
string
required
Possible values: [DeleteAgentInstance]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=DeleteAgentInstance

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentInstanceId
string
required
The unique identifier of the AI agent instance, obtained through the response parameters of the Create AI Agent Instance interface.

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID
API Reference
Agent Instance Control
Trigger LLM
SendAgentInstanceLLM
POST
https://aigc-aiagent-api.zegotech.cn/
This interface can be used to, as the user, actively call the LLM service, and based on the response content of the LLM, actively call the TTS service as the AI agent, and send voice messages to the user. (1. When this interface is called, if the AI agent in the conversation is speaking, the speaking process of the AI agent will be interrupted; 2. The text information passed into this interface will not be recorded in the conversation history message and will not be sent through the RTC room message. However, the reply generated by the LLM will be recorded in the conversation history message and sent through the RTC room message.)

Request
Query Parameters
Action
string
required
Possible values: [SendAgentInstanceLLM]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=SendAgentInstanceLLM

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentInstanceId
string
required
The unique identifier of the AI agent instance, obtained through the response parameters of the Create AI Agent Instance interface.

Text
string
required
The text content sent to the LLM service

SystemPrompt
string
Whether to temporarily modify the system prompt of the AI agent for this conversation, if needed, fill in this field. If left blank, the system prompt of this conversation will not be changed.

AddQuestionToHistory
boolean
Default value: false

Whether to add the question to the context

AddAnswerToHistory
boolean
Default value: false

Whether to add the answer to the context

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID
API Reference
Agent Instance Control
Trigger TTS
SendAgentInstanceTTS
POST
https://aigc-aiagent-api.zegotech.cn/
This interface can be used to actively call the TTS service to send voice messages as the identity of the AI agent. (1. When this interface is called, if the AI agent in the conversation is speaking, the speaking process of the AI agent will be interrupted; 2. The text message passed in through this interface will be recorded in the conversation message history according to the AddHistory parameter, as input to the LLM, and the message will also be sent through the RTC room message.)

Request
Query Parameters
Action
string
required
Possible values: [SendAgentInstanceTTS]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=SendAgentInstanceTTS

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentInstanceId
string
required
The unique identifier of the AI agent instance, obtained through the response parameters of the Create AI Agent Instance interface.

Text
string
required
Possible values: <= 300 characters

The text content used for TTS, with a maximum of 300 characters.

AddHistory
boolean
Default value: true

Whether to record the text message in the conversation message history as input to the LLM.

InterruptMode
integer
Default value: 0

The mode of interruption when the AI agent is speaking:

0: Interrupt immediately. If the user speaks while the AI is speaking, the AI will be immediately interrupted and stop speaking (default).
1: Do not interrupt. If the user speaks while the AI is speaking, the AI will not be affected until the content is finished.
Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID
API Reference
Agent Instance Control
Query The Status of An AI Agent Instance
QueryAgentInstanceStatus
POST
https://aigc-aiagent-api.zegotech.cn/
This interface is used to query the running status information of the AI agent instance in a voice conversation.

Request
Query Parameters
Action
string
required
Possible values: [QueryAgentInstanceStatus]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=QueryAgentInstanceStatus

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentInstanceId
string
required
The unique identifier of the AI agent instance, obtained through the response parameters of the Create AI Agent Instance interface.

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID

Data
object
API Reference
Agent Instance Control
Interrupt Agent Instance
InterruptAgentInstance
POST
https://aigc-aiagent-api.zegotech.cn/
This interface is used to interrupt the AI agent instance in a voice conversation.

Request
Query Parameters
Action
string
required
Possible values: [InterruptAgentInstance]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=InterruptAgentInstance

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentInstanceId
string
required
The unique identifier of the AI agent instance, obtained through the response parameters of the Create AI Agent Instance interface.

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID
API Reference
Agent Instance Control
Get Agent Instance Context
GetAgentInstanceMsgList
POST
https://aigc-aiagent-api.zegotech.cn/
This interface is used to obtain the message list used as context when interacting with the AI agent instance.

Request
Query Parameters
Action
string
required
Possible values: [GetAgentInstanceMsgList]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=GetAgentInstanceMsgList

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentInstanceId
string
required
The unique identifier of the AI agent instance, obtained through the response parameters of the Create AI Agent Instance interface.

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Example
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID

Data
object
API Reference
Agent Instance Control
Reset Agent Instance Context
ResetAgentInstanceMsgList
POST
https://aigc-aiagent-api.zegotech.cn/
This interface is used to reset the message list used as context when interacting with the AI agent instance.

Request
Query Parameters
Action
string
required
Possible values: [ResetAgentInstanceMsgList]

API Prototype Parameter

https://aigc-aiagent-api.zegotech.cn?Action=ResetAgentInstanceMsgList

AppId
uint32
required
The unique Application ID assigned to your project by ZEGOCLOUD. Get it from the ZEGOCLOUD Admin Console.

SignatureNonce
string
required
Random string.

Timestamp
int64
required
Unix timestamp, in seconds. The maximum allowed error is 10 minutes.

Signature
string
required
Signature, used to verify the legitimacy of the request. Refer to Signing the requests for how to generate an API request signature.

SignatureVersion
string
required
Possible values: [2.0]

Signature version number, default value is 2.0.

application/json
Body
required
AgentInstanceId
string
required
The unique identifier of the AI agent instance, obtained through the response parameters of the Create AI Agent Instance interface.

Responsesâ€‹
200
Success
application/json
Schema
Example (from schema)
Schema
Code
integer
Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to Return Codes.

Message
string
Explanation of the request result

RequestId
string
Request ID
Callback
Receiving Callback
Receiving Callback
Warning
The callback service cannot guarantee complete reliability. Please carefully consider the risks of building core business processes using the callback solution.
With this callback, you can listen to events that occur during user conversations with the agent, including ASR results, LLM results, exception events, agent interruption events, user speaking actions, agent speaking actions, user speaking audio data, agent instance created, and agent instance deleted.

Note
To receive different types of callback results, configure the corresponding CallbackConfig parameter to 1 when creating an agent instance:

ASR results: CallbackConfig.ASRResult
LLM results: CallbackConfig.LLMResult
Agent interruption events: CallbackConfig.Interrupted
User speaking actions: CallbackConfig.UserSpeakAction
Agent speaking actions: CallbackConfig.AgentSpeakAction
User speaking audio data: CallbackConfig.UserAudioData
Callback Description
Request method: POST.
Note
The callback data format is JSON. You need to perform UrlDecode decoding on it.
Request URL: Please contact ZEGOCLOUD Technical Support for configuration.
Transmission protocol: HTTPS/HTTP, it is recommended to use HTTPS.
Callback Parameters
Note
ZEGOCLOUD will continuously optimize and update the relevant callback parameters in future iteration plans (for example: adding new fields or adding parameter values for certain fields). When developers integrate, please avoid hardcoding to ensure compatibility with new versions after updates.
Parameter	Type	Description
AppId	Number	The unique identifier for the developer's APP provided by ZEGOCLOUD.
Event	String	Notification type of event.
ASRResult: Callback for ASR results.
LLMResult: Callback for LLM results.
Exception: Exception event.
Interrupted: Callback for agent interruption results.
UserSpeakAction: Callback for user speaking events.
AgentSpeakAction: Callback for agent speaking events.
UserAudioData: Callback for user speaking audio data.
AgentInstanceCreated: Agent instance created.
AgentInstanceDeleted: Agent instance deleted.
Nonce	String	A random number used for signature calculation.
Timestamp	Number	Unix timestamp (in milliseconds) when the callback was sent, used for signature calculation.
Signature	String	Verification string to confirm the identity of the sender of the callback.
AgentInstanceId	String	The unique identifier for the AI agent instance.
AgentUserId	String	The user ID of the AI agent.
RoomId	String	The room ID.
Sequence	Number	The sequence number of the callback, ensuring orderliness but not necessarily continuity.
Data	Object	Detailed information about the event. For details, see Data.
Data
Depending on the different values of Event, the parameters included in Data are different.

ASRResult
LLMResult
Exception
Interrupted
UserSpeakAction
AgentSpeakAction
UserAudioData
AgentInstanceCreated
AgentInstanceDeleted

Parameter	Type	Description
UserId	String	The speaker's user ID.
Round	Number	The dialogue round number. It increases each time the user starts speaking (ordered, not necessarily incremental).
Text	String	ASR result text.

Callback Examples
Below are callback examples for each Event type.

ASRResult
LLMResult
Exception
Interrupted
UserSpeakAction
AgentSpeakAction
UserAudioData
AgentInstanceCreated
AgentInstanceDeleted

{
    "AppId": 1234567,
    "AgentInstanceId": "1912124734317838336",
    "Data": {
        "UserId": "user_1",
        "Round": 650459806,
        "Text": "Hello"
    },
    "Event": "ASRResult",
    "Nonce": "7450395512627324902",
    "Signature": "fd9c1ce54e85bd92f48b0a805e82a52b0c0c6445",
    "Timestamp": 1745502313000
}

{
    "AppId": 1234567,
    "AgentInstanceId": "1912124734317838336",
    "Data": {
        "UserId": "user_1",
        "Round": 650459806,
        "Text": "Hello"
    },
    "Event": "ASRResult",
    "Nonce": "7450395512627324902",
    "Signature": "fd9c1ce54e85bd92f48b0a805e82a52b0c0c6445",
    "Timestamp": 1745502313000
}
Signature Verification
To enhance data security, developers should perform local signature calculations when receiving callbacks from the ZEGOCLOUD server, and compare them with the provided signature to determine if the request is legitimate.

The verification process is as follows:

1
Sort parameters

Sort the three parameters callbacksecret, timestamp, and nonce in dictionary order

2
Calculate SHA1

Concatenate the sorted callbacksecret, timestamp, and nonce into a string and calculate SHA1

3
Compare signature

Compare the calculated hash string with signature, if they match, the request is from ZEGOCLOUD

The parameters are described as follows:

Parameter	Description
callbacksecret	Server verification key. Generated when registering a project in the ZEGOCLOUD Console. You can view it in "Console > Project Configuration > Project Information > Configuration Information".
timestamp	Unix timestamp.
nonce	Random number.
Usage Example

PHP Example
// Get signature, timestamp, nonce from request parameters
$signature = $_POST["signature"];
$timestamp = $_POST["timestamp"];
$nonce = $_POST["nonce"];

$secret = callbacksecret;// Get callbacksecret from console
$tmpArr = array($secret, $timestamp, $nonce);
sort($tmpArr, SORT_STRING);
$tmpStr = implode( $tmpArr );
$tmpStr = sha1( $tmpStr );

if( $tmpStr == $signature ){
    return true;
} else {
    return false;
}


PHP Example
$nonce = 123412;
$timestamp = 1470820198;
$secret = 'secret';
// The order of the three parameters after sorting is: nonce, timestamp, secret
// The original string to be encrypted after sorting and concatenation is: 1234121470820198secret
// The result of the hash calculation is: 5bd59fd62953a8059fb7eaba95720f66d19e4517

Return Response
After you receive the callback, please return an HTTP status code of 2XX (e.g., 200) to indicate successful receipt. Any other response will be considered a failure.

Callback Retry Policy
If the ZEGOCLOUD server does not receive a response, or if the received HTTP status code is not 2XX (e.g., 200), it will attempt to retry, with a maximum of 5 retries. The interval between each retry request and the previous request will be 2s, 4s, 8s, 16s, and 32s respectively. If the 5th retry still fails, no further retries will be attempted, and the callback will be lost.
Callback
Exception Event Codes
Exception Codes
This document lists the exception event codes that may occur during the operation of the AI agent instance and provides handling suggestions. For information about receiving exception event callbacks, please refer to Receiving Callback.

Event Code	Event Name	Suggested Action
1001	ZEGOCLOUD AI Agent General Error	Refer to the Message field for details.
1004	Server VAD detects human voice but ASR fails to recognize valid text	The server VAD detects human voice but ASR fails to recognize valid text.
1101	IM General Error	Please provide the Message field to ZEGOCLOUD Technical Support.
1201	RTC General Error	Please provide the Message field to ZEGOCLOUD Technical Support.
1202	RTC room has been idle for over 120 seconds.	Please check if there are real users in the RTC room.
1203	AI agent instance was removed from the RTC room.	Please check if multiple AI agent instances use the same AgentUserId.
1204	AI agent instance failed to log into the RTC room.	Please provide the Message field to ZEGOCLOUD Technical Support.
1205	AI agent instance disconnected from the RTC room.	Please provide the Message field to ZEGOCLOUD Technical Support.
1206	AI agent instance failed to push stream.	Please provide the Message field to ZEGOCLOUD Technical Support.
1207	AI agent instance failed to pull stream.	Please provide the Message field to ZEGOCLOUD Technical Support.
2101	ASR General Error	Please provide the Message field to ZEGOCLOUD Technical Support.
2201	LLM General Error	Refer to the Message field for details.
2202	LLM Parameter Error	Please check if the request parameters are valid.
2203	LLM Request Authentication Failed	Please check if the provided LLM.ApiKey is correct.
2204	LLM Request Concurrency Reached Limit	Please confirm whether additional concurrency needs to be purchased.
2205	LLM Account Overdue	Please go to the official website of the LLM service provider to renew your subscription.
2206	LLM Content Review Failed	Please check if the user input contains illegal content.
2301	TTS General Error	Refer to the Message field for details.
2302	TTS Parameter Error	Please check if the request parameters are valid.
2303	TTS Request Authentication Failed	Please check if the provided TTS.Params.app is correct.
2304	TTS Request Concurrency Reached Limit	Please confirm whether additional concurrency needs to be purchased.
2305	TTS Account Overdue	Please go to the official website of the TTS service provider to renew your subscription.
410001003	Failed to create digital human.	Please contact ZEGOCLOUD technical support for processing.
410001026	Digital human ConfigId not supported.	Please contact ZEGOCLOUD technical support to confirm whether the corresponding ConfigId is supported by the digital human.
410001025	Concurrent number insufficient.	Please confirm whether the concurrent number exceeds the limit.
410001027	Digital human DigitalHumanId is incorrect.	Please confirm whether the DigitalHumanId is correct.